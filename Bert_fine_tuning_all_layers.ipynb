{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Bert_fine_tuning_all_layers.ipynb","version":"0.3.2","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"TPU"},"cells":[{"cell_type":"code","metadata":{"id":"Dm2ZcUlr55EO","colab_type":"code","outputId":"a6458eb5-248d-4812-c252-f7b5aa7537d7","executionInfo":{"status":"ok","timestamp":1566665063072,"user_tz":-540,"elapsed":1888,"user":{"displayName":"Junha Hyung","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCW-Idc2Xb4naFmTr7ifom9YCmu_ffuOK2Tterv3Q=s64","userId":"06504932993766290160"}},"colab":{"base_uri":"https://localhost:8080/","height":293}},"source":["import datetime\n","import json\n","import os\n","import pprint\n","import random\n","import string\n","import sys\n","import csv\n","import pandas as pd\n","import tensorflow as tf\n","\n","assert 'COLAB_TPU_ADDR' in os.environ, 'ERROR: Not connected to a TPU runtime; please see the first cell in this notebook for instructions!'\n","TPU_ADDRESS = 'grpc://' + os.environ['COLAB_TPU_ADDR']\n","print('TPU address is', TPU_ADDRESS)\n","\n","from google.colab import auth\n","auth.authenticate_user()\n","with tf.Session(TPU_ADDRESS) as session:\n","  print('TPU devices:')\n","  pprint.pprint(session.list_devices())\n","\n","  # Upload credentials to TPU.\n","  with open('/content/adc.json', 'r') as f:\n","    auth_info = json.load(f)\n","  tf.contrib.cloud.configure_gcs(session, credentials=auth_info)\n","  # Now credentials are set for all future sessions on this TPU."],"execution_count":9,"outputs":[{"output_type":"stream","text":["TPU address is grpc://10.20.251.2:8470\n","TPU devices:\n","[_DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:CPU:0, CPU, -1, 5461397410893345720),\n"," _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 4046163905499687783),\n"," _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, 6334001938828563839),\n"," _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, 7970280152128682818),\n"," _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, 10019469512384429314),\n"," _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, 5821903356188235848),\n"," _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 2280110011057253458),\n"," _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, 2058815119083188750),\n"," _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 7142539314270572659),\n"," _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, 790707899119014422),\n"," _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 8589934592, 9474050468988280264)]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"LmPmHdhf6xj9","colab_type":"code","outputId":"1d0b95af-7b2b-4017-9b84-921372ceac4e","executionInfo":{"status":"ok","timestamp":1566665066455,"user_tz":-540,"elapsed":5257,"user":{"displayName":"Junha Hyung","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCW-Idc2Xb4naFmTr7ifom9YCmu_ffuOK2Tterv3Q=s64","userId":"06504932993766290160"}},"colab":{"base_uri":"https://localhost:8080/","height":266}},"source":["import sys\n","from os import listdir\n","!rm -rf bert_finetune\n","!test -d bert_finetune || git clone https://github.com/junhahyung/bert_finetune bert_finetune\n","if not 'bert_finetune' in sys.path:\n","  sys.path += ['bert_finetune']\n","print(listdir(\"bert_finetune\"))\n","# import python modules defined by BERT\n","import modeling\n","import optimization\n","import run_classifier\n","import run_classifier_with_tfhub\n","import tokenization\n","\n","# import tfhub \n","import tensorflow_hub as hub"],"execution_count":10,"outputs":[{"output_type":"stream","text":["Cloning into 'bert_finetune'...\n","remote: Enumerating objects: 88, done.\u001b[K\n","remote: Counting objects:   1% (1/88)\u001b[K\rremote: Counting objects:   2% (2/88)\u001b[K\rremote: Counting objects:   3% (3/88)\u001b[K\rremote: Counting objects:   4% (4/88)\u001b[K\rremote: Counting objects:   5% (5/88)\u001b[K\rremote: Counting objects:   6% (6/88)\u001b[K\rremote: Counting objects:   7% (7/88)\u001b[K\rremote: Counting objects:   9% (8/88)\u001b[K\rremote: Counting objects:  10% (9/88)\u001b[K\rremote: Counting objects:  11% (10/88)\u001b[K\rremote: Counting objects:  12% (11/88)\u001b[K\rremote: Counting objects:  13% (12/88)\u001b[K\rremote: Counting objects:  14% (13/88)\u001b[K\rremote: Counting objects:  15% (14/88)\u001b[K\rremote: Counting objects:  17% (15/88)\u001b[K\rremote: Counting objects:  18% (16/88)\u001b[K\rremote: Counting objects:  19% (17/88)\u001b[K\rremote: Counting objects:  20% (18/88)\u001b[K\rremote: Counting objects:  21% (19/88)\u001b[K\rremote: Counting objects:  22% (20/88)\u001b[K\rremote: Counting objects:  23% (21/88)\u001b[K\rremote: Counting objects:  25% (22/88)\u001b[K\rremote: Counting objects:  26% (23/88)\u001b[K\rremote: Counting objects:  27% (24/88)\u001b[K\rremote: Counting objects:  28% (25/88)\u001b[K\rremote: Counting objects:  29% (26/88)\u001b[K\rremote: Counting objects:  30% (27/88)\u001b[K\rremote: Counting objects:  31% (28/88)\u001b[K\rremote: Counting objects:  32% (29/88)\u001b[K\rremote: Counting objects:  34% (30/88)\u001b[K\rremote: Counting objects:  35% (31/88)\u001b[K\rremote: Counting objects:  36% (32/88)\u001b[K\rremote: Counting objects:  37% (33/88)\u001b[K\rremote: Counting objects:  38% (34/88)\u001b[K\rremote: Counting objects:  39% (35/88)\u001b[K\rremote: Counting objects:  40% (36/88)\u001b[K\rremote: Counting objects:  42% (37/88)\u001b[K\rremote: Counting objects:  43% (38/88)\u001b[K\rremote: Counting objects:  44% (39/88)\u001b[K\rremote: Counting objects:  45% (40/88)\u001b[K\rremote: Counting objects:  46% (41/88)\u001b[K\rremote: Counting objects:  47% (42/88)\u001b[K\rremote: Counting objects:  48% (43/88)\u001b[K\rremote: Counting objects:  50% (44/88)\u001b[K\rremote: Counting objects:  51% (45/88)\u001b[K\rremote: Counting objects:  52% (46/88)\u001b[K\rremote: Counting objects:  53% (47/88)\u001b[K\rremote: Counting objects:  54% (48/88)\u001b[K\rremote: Counting objects:  55% (49/88)\u001b[K\rremote: Counting objects:  56% (50/88)\u001b[K\rremote: Counting objects:  57% (51/88)\u001b[K\rremote: Counting objects:  59% (52/88)\u001b[K\rremote: Counting objects:  60% (53/88)\u001b[K\rremote: Counting objects:  61% (54/88)\u001b[K\rremote: Counting objects:  62% (55/88)\u001b[K\rremote: Counting objects:  63% (56/88)\u001b[K\rremote: Counting objects:  64% (57/88)\u001b[K\rremote: Counting objects:  65% (58/88)\u001b[K\rremote: Counting objects:  67% (59/88)\u001b[K\rremote: Counting objects:  68% (60/88)\u001b[K\rremote: Counting objects:  69% (61/88)\u001b[K\rremote: Counting objects:  70% (62/88)\u001b[K\rremote: Counting objects:  71% (63/88)\u001b[K\rremote: Counting objects:  72% (64/88)\u001b[K\rremote: Counting objects:  73% (65/88)\u001b[K\rremote: Counting objects:  75% (66/88)\u001b[K\rremote: Counting objects:  76% (67/88)\u001b[K\rremote: Counting objects:  77% (68/88)\u001b[K\rremote: Counting objects:  78% (69/88)\u001b[K\rremote: Counting objects:  79% (70/88)\u001b[K\rremote: Counting objects:  80% (71/88)\u001b[K\rremote: Counting objects:  81% (72/88)\u001b[K\rremote: Counting objects:  82% (73/88)\u001b[K\rremote: Counting objects:  84% (74/88)\u001b[K\rremote: Counting objects:  85% (75/88)\u001b[K\rremote: Counting objects:  86% (76/88)\u001b[K\rremote: Counting objects:  87% (77/88)\u001b[K\rremote: Counting objects:  88% (78/88)\u001b[K\rremote: Counting objects:  89% (79/88)\u001b[K\rremote: Counting objects:  90% (80/88)\u001b[K\rremote: Counting objects:  92% (81/88)\u001b[K\rremote: Counting objects:  93% (82/88)\u001b[K\rremote: Counting objects:  94% (83/88)\u001b[K\rremote: Counting objects:  95% (84/88)\u001b[K\rremote: Counting objects:  96% (85/88)\u001b[K\rremote: Counting objects:  97% (86/88)\u001b[K\rremote: Counting objects:  98% (87/88)\u001b[K\rremote: Counting objects: 100% (88/88)\u001b[K\rremote: Counting objects: 100% (88/88), done.\u001b[K\n","remote: Compressing objects:   1% (1/65)\u001b[K\rremote: Compressing objects:   3% (2/65)\u001b[K\rremote: Compressing objects:   4% (3/65)\u001b[K\rremote: Compressing objects:   6% (4/65)\u001b[K\rremote: Compressing objects:   7% (5/65)\u001b[K\rremote: Compressing objects:   9% (6/65)\u001b[K\rremote: Compressing objects:  10% (7/65)\u001b[K\rremote: Compressing objects:  12% (8/65)\u001b[K\rremote: Compressing objects:  13% (9/65)\u001b[K\rremote: Compressing objects:  15% (10/65)\u001b[K\rremote: Compressing objects:  16% (11/65)\u001b[K\rremote: Compressing objects:  18% (12/65)\u001b[K\rremote: Compressing objects:  20% (13/65)\u001b[K\rremote: Compressing objects:  21% (14/65)\u001b[K\rremote: Compressing objects:  23% (15/65)\u001b[K\rremote: Compressing objects:  24% (16/65)\u001b[K\rremote: Compressing objects:  26% (17/65)\u001b[K\rremote: Compressing objects:  27% (18/65)\u001b[K\rremote: Compressing objects:  29% (19/65)\u001b[K\rremote: Compressing objects:  30% (20/65)\u001b[K\rremote: Compressing objects:  32% (21/65)\u001b[K\rremote: Compressing objects:  33% (22/65)\u001b[K\rremote: Compressing objects:  35% (23/65)\u001b[K\rremote: Compressing objects:  36% (24/65)\u001b[K\rremote: Compressing objects:  38% (25/65)\u001b[K\rremote: Compressing objects:  40% (26/65)\u001b[K\rremote: Compressing objects:  41% (27/65)\u001b[K\rremote: Compressing objects:  43% (28/65)\u001b[K\rremote: Compressing objects:  44% (29/65)\u001b[K\rremote: Compressing objects:  46% (30/65)\u001b[K\rremote: Compressing objects:  47% (31/65)\u001b[K\rremote: Compressing objects:  49% (32/65)\u001b[K\rremote: Compressing objects:  50% (33/65)\u001b[K\rremote: Compressing objects:  52% (34/65)\u001b[K\rremote: Compressing objects:  53% (35/65)\u001b[K\rremote: Compressing objects:  55% (36/65)\u001b[K\rremote: Compressing objects:  56% (37/65)\u001b[K\rremote: Compressing objects:  58% (38/65)\u001b[K\rremote: Compressing objects:  60% (39/65)\u001b[K\rremote: Compressing objects:  61% (40/65)\u001b[K\rremote: Compressing objects:  63% (41/65)\u001b[K\rremote: Compressing objects:  64% (42/65)\u001b[K\rremote: Compressing objects:  66% (43/65)\u001b[K\rremote: Compressing objects:  67% (44/65)\u001b[K\rremote: Compressing objects:  69% (45/65)\u001b[K\rremote: Compressing objects:  70% (46/65)\u001b[K\rremote: Compressing objects:  72% (47/65)\u001b[K\rremote: Compressing objects:  73% (48/65)\u001b[K\rremote: Compressing objects:  75% (49/65)\u001b[K\rremote: Compressing objects:  76% (50/65)\u001b[K\rremote: Compressing objects:  78% (51/65)\u001b[K\rremote: Compressing objects:  80% (52/65)\u001b[K\rremote: Compressing objects:  81% (53/65)\u001b[K\rremote: Compressing objects:  83% (54/65)\u001b[K\rremote: Compressing objects:  84% (55/65)\u001b[K\rremote: Compressing objects:  86% (56/65)\u001b[K\rremote: Compressing objects:  87% (57/65)\u001b[K\rremote: Compressing objects:  89% (58/65)\u001b[K\rremote: Compressing objects:  90% (59/65)\u001b[K\rremote: Compressing objects:  92% (60/65)\u001b[K\rremote: Compressing objects:  93% (61/65)\u001b[K\rremote: Compressing objects:  95% (62/65)\u001b[K\rremote: Compressing objects:  96% (63/65)\u001b[K\rremote: Compressing objects:  98% (64/65)\u001b[K\rremote: Compressing objects: 100% (65/65)\u001b[K\rremote: Compressing objects: 100% (65/65), done.\u001b[K\n","Unpacking objects:   1% (1/88)   \rUnpacking objects:   2% (2/88)   \rUnpacking objects:   3% (3/88)   \rUnpacking objects:   4% (4/88)   \rUnpacking objects:   5% (5/88)   \rUnpacking objects:   6% (6/88)   \rUnpacking objects:   7% (7/88)   \rUnpacking objects:   9% (8/88)   \rUnpacking objects:  10% (9/88)   \rUnpacking objects:  11% (10/88)   \rUnpacking objects:  12% (11/88)   \rUnpacking objects:  13% (12/88)   \rUnpacking objects:  14% (13/88)   \rUnpacking objects:  15% (14/88)   \rUnpacking objects:  17% (15/88)   \rUnpacking objects:  18% (16/88)   \rUnpacking objects:  19% (17/88)   \rUnpacking objects:  20% (18/88)   \rUnpacking objects:  21% (19/88)   \rUnpacking objects:  22% (20/88)   \rUnpacking objects:  23% (21/88)   \rUnpacking objects:  25% (22/88)   \rUnpacking objects:  26% (23/88)   \rUnpacking objects:  27% (24/88)   \rUnpacking objects:  28% (25/88)   \rUnpacking objects:  29% (26/88)   \rUnpacking objects:  30% (27/88)   \rUnpacking objects:  31% (28/88)   \rUnpacking objects:  32% (29/88)   \rUnpacking objects:  34% (30/88)   \rUnpacking objects:  35% (31/88)   \rUnpacking objects:  36% (32/88)   \rUnpacking objects:  37% (33/88)   \rUnpacking objects:  38% (34/88)   \rUnpacking objects:  39% (35/88)   \rUnpacking objects:  40% (36/88)   \rUnpacking objects:  42% (37/88)   \rUnpacking objects:  43% (38/88)   \rUnpacking objects:  44% (39/88)   \rUnpacking objects:  45% (40/88)   \rUnpacking objects:  46% (41/88)   \rUnpacking objects:  47% (42/88)   \rUnpacking objects:  48% (43/88)   \rUnpacking objects:  50% (44/88)   \rremote: Total 88 (delta 38), reused 50 (delta 17), pack-reused 0\u001b[K\n","Unpacking objects:  51% (45/88)   \rUnpacking objects:  52% (46/88)   \rUnpacking objects:  53% (47/88)   \rUnpacking objects:  54% (48/88)   \rUnpacking objects:  55% (49/88)   \rUnpacking objects:  56% (50/88)   \rUnpacking objects:  57% (51/88)   \rUnpacking objects:  59% (52/88)   \rUnpacking objects:  60% (53/88)   \rUnpacking objects:  61% (54/88)   \rUnpacking objects:  62% (55/88)   \rUnpacking objects:  63% (56/88)   \rUnpacking objects:  64% (57/88)   \rUnpacking objects:  65% (58/88)   \rUnpacking objects:  67% (59/88)   \rUnpacking objects:  68% (60/88)   \rUnpacking objects:  69% (61/88)   \rUnpacking objects:  70% (62/88)   \rUnpacking objects:  71% (63/88)   \rUnpacking objects:  72% (64/88)   \rUnpacking objects:  73% (65/88)   \rUnpacking objects:  75% (66/88)   \rUnpacking objects:  76% (67/88)   \rUnpacking objects:  77% (68/88)   \rUnpacking objects:  78% (69/88)   \rUnpacking objects:  79% (70/88)   \rUnpacking objects:  80% (71/88)   \rUnpacking objects:  81% (72/88)   \rUnpacking objects:  82% (73/88)   \rUnpacking objects:  84% (74/88)   \rUnpacking objects:  85% (75/88)   \rUnpacking objects:  86% (76/88)   \rUnpacking objects:  87% (77/88)   \rUnpacking objects:  88% (78/88)   \rUnpacking objects:  89% (79/88)   \rUnpacking objects:  90% (80/88)   \rUnpacking objects:  92% (81/88)   \rUnpacking objects:  93% (82/88)   \rUnpacking objects:  94% (83/88)   \rUnpacking objects:  95% (84/88)   \rUnpacking objects:  96% (85/88)   \rUnpacking objects:  97% (86/88)   \rUnpacking objects:  98% (87/88)   \rUnpacking objects: 100% (88/88)   \rUnpacking objects: 100% (88/88), done.\n","['create_pretraining_data.py', 'sample_text.txt', '.gitignore', 'run_classifier.py', 'optimization_test.py', 'modeling_test.py', '__init__.pyc', 'LICENSE', 'optimization.py', '__init__.py', 'run_classifier_with_tfhub.py', 'tokenization.py', 'extract_features.py', 'run_pretraining.py', 'multilingual.md', 'README.md', 'modeling.py', 'run_squad.py', 'CONTRIBUTING.md', 'requirements.txt', 'tokenization_test.py', 'predicting_movie_reviews_with_bert_on_tf_hub.ipynb', '.git', 'modeling.pyc']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"61BoPlzHC0bT","colab_type":"code","outputId":"50afc540-42bc-4342-a4a8-705292a0f24c","executionInfo":{"status":"ok","timestamp":1566665066825,"user_tz":-540,"elapsed":5616,"user":{"displayName":"Junha Hyung","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCW-Idc2Xb4naFmTr7ifom9YCmu_ffuOK2Tterv3Q=s64","userId":"06504932993766290160"}},"colab":{"base_uri":"https://localhost:8080/","height":113}},"source":["TASK = 'korean_sa'\n","assert TASK in ('MRPC', 'CoLA', 'korean_sa'), 'Undefined task'\n","\n","BUCKET = 'mbertfinetune' #@param {type:\"string\"}\n","assert BUCKET, 'Must specify an existing GCS bucket name'\n","TASK_DATA_DIR = 'gs://{}/data/{}'.format(BUCKET, TASK)\n","print('***** Task data directory: {} *****'.format(TASK_DATA_DIR))\n","print(tf.gfile.ListDirectory(TASK_DATA_DIR))\n","OUTPUT_DIR = 'gs://{}/bert-tfhub-all_layers/models/{}'.format(BUCKET, TASK)\n","tf.gfile.MakeDirs(OUTPUT_DIR)\n","print('***** Model output directory: {} *****'.format(OUTPUT_DIR))\n","\n","BERT_MODEL = 'multi_cased_L-12_H-768_A-12'\n","BERT_MODEL_HUB = 'https://tfhub.dev/google/bert_' + BERT_MODEL + '/1'\n","\n","CKPT_DIR = 'gs://{}/{}/bert_model.ckpt'.format(BUCKET, BERT_MODEL)\n","CONFIG_DIR = 'gs://{}/{}/bert_config.json'.format(BUCKET, BERT_MODEL)\n","\"\"\"\n","tdir = os.path.join(TASK_DATA_DIR, \"korean_train.csv\")\n","with tf.gfile.Open(tdir, \"r\") as f:\n","  reader = pd.read_csv(tdir) \n","  lines = []\n","  for line in reader:\n","    lines.append(line)\n","print(lines[18824])\n","\"\"\""],"execution_count":11,"outputs":[{"output_type":"stream","text":["***** Task data directory: gs://mbertfinetune/data/korean_sa *****\n","['korean_dev.csv', 'korean_train.csv']\n","***** Model output directory: gs://mbertfinetune/bert-tfhub-all_layers/models/korean_sa *****\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["'\\ntdir = os.path.join(TASK_DATA_DIR, \"korean_train.csv\")\\nwith tf.gfile.Open(tdir, \"r\") as f:\\n  reader = pd.read_csv(tdir) \\n  lines = []\\n  for line in reader:\\n    lines.append(line)\\nprint(lines[18824])\\n'"]},"metadata":{"tags":[]},"execution_count":11}]},{"cell_type":"code","metadata":{"id":"_JLqv7pBUiHH","colab_type":"code","outputId":"494bd5fd-7a61-4c68-fd52-eddc251662e9","executionInfo":{"status":"ok","timestamp":1566665114280,"user_tz":-540,"elapsed":53061,"user":{"displayName":"Junha Hyung","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCW-Idc2Xb4naFmTr7ifom9YCmu_ffuOK2Tterv3Q=s64","userId":"06504932993766290160"}},"colab":{"base_uri":"https://localhost:8080/","height":94}},"source":["tokenizer = run_classifier_with_tfhub.create_tokenizer_from_hub_module(BERT_MODEL_HUB)\n","tokenizer.tokenize(\"한국어는 잘 안되는 것 같아요.\")"],"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['한국', '##어는', '잘', '안', '##되는', '것', '같', '##아', '##요', '.']"]},"metadata":{"tags":[]},"execution_count":12}]},{"cell_type":"code","metadata":{"id":"52yngvKU41ha","colab_type":"code","colab":{}},"source":["TRAIN_BATCH_SIZE = 32\n","EVAL_BATCH_SIZE = 8\n","PREDICT_BATCH_SIZE = 8\n","LEARNING_RATE = 2e-5\n","NUM_TRAIN_EPOCHS = 3\n","MAX_SEQ_LENGTH = 128\n","# Warmup is a period of time where hte learning rate \n","# is small and gradually increases--usually helps training.\n","WARMUP_PROPORTION = 0.1\n","# Model configs\n","SAVE_CHECKPOINTS_STEPS = 1000\n","SAVE_SUMMARY_STEPS = 500\n","# layer_wise_lr = (True, 0.3)\n","# layer_wise_lr = None \n","\n","processors = {\n","  \"cola\": run_classifier.ColaProcessor,\n","  \"mnli\": run_classifier.MnliProcessor,\n","  \"mrpc\": run_classifier.MrpcProcessor,\n","  \"korean_sa\": run_classifier.KsaProcessor,\n","}\n","processor = processors[TASK.lower()]()\n","label_list = processor.get_labels()\n","\n","processor.get_train_examples(TASK_DATA_DIR)\n","# Compute number of train and warmup steps from batch size\n","train_examples = processor.get_train_examples(TASK_DATA_DIR)\n","num_train_steps = int(len(train_examples) / TRAIN_BATCH_SIZE * NUM_TRAIN_EPOCHS)\n","num_warmup_steps = int(num_train_steps * WARMUP_PROPORTION)\n","\n","tpu_cluster_resolver = tf.contrib.cluster_resolver.TPUClusterResolver(TPU_ADDRESS)\n","NUM_TPU_CORES = 8\n","ITERATIONS_PER_LOOP = 1000 \n","\n","def get_run_config(output_dir):  \n","  return tf.contrib.tpu.RunConfig(    \n","      cluster=tpu_cluster_resolver,    \n","      model_dir=output_dir,    \n","      save_checkpoints_steps=SAVE_CHECKPOINTS_STEPS,    \n","      tpu_config=tf.contrib.tpu.TPUConfig(        \n","          iterations_per_loop=ITERATIONS_PER_LOOP,        \n","          num_shards=NUM_TPU_CORES,        \n","          per_host_input_for_training=tf.contrib.tpu.InputPipelineConfig.PER_HOST_V2))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZWIM2qnzMsbH","colab_type":"code","outputId":"6f4985a7-f030-4a1e-9ae2-75fc0731b0a2","executionInfo":{"status":"ok","timestamp":1566665115303,"user_tz":-540,"elapsed":54063,"user":{"displayName":"Junha Hyung","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCW-Idc2Xb4naFmTr7ifom9YCmu_ffuOK2Tterv3Q=s64","userId":"06504932993766290160"}},"colab":{"base_uri":"https://localhost:8080/","height":74}},"source":["os.environ['TFHUB_CACHE_DIR'] = OUTPUT_DIR \n","bert_config = modeling.BertConfig.from_json_file(CONFIG_DIR)\n","\n","model_fn = run_classifier.model_fn_builder(  \n","    bert_config=bert_config,\n","    num_labels=len(label_list),  \n","    init_checkpoint=CKPT_DIR,\n","    learning_rate=LEARNING_RATE,  \n","    num_train_steps=num_train_steps,  \n","    num_warmup_steps=num_warmup_steps,  \n","    use_tpu=True,  \n","    use_one_hot_embeddings=True,\n","    use_all_layers=True\n",")\n","\n","estimator = tf.contrib.tpu.TPUEstimator(\n","  use_tpu=True,\n","  model_fn=model_fn,\n","  config=get_run_config(OUTPUT_DIR),\n","  train_batch_size=TRAIN_BATCH_SIZE,\n","  eval_batch_size=EVAL_BATCH_SIZE,\n","  predict_batch_size=PREDICT_BATCH_SIZE,\n",")"],"execution_count":14,"outputs":[{"output_type":"stream","text":["W0824 16:45:14.930127 140709399074688 estimator.py:1984] Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7ff9298946a8>) includes params argument, but params are not passed to Estimator.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"6pVcvhIOOyzn","colab_type":"code","colab":{}},"source":["# Train the model\n","def model_train(estimator):\n","  print('Please wait...')\n","  # We'll set sequences to be at most 128 tokens long.\n","  train_features = run_classifier.convert_examples_to_features(\n","      train_examples, label_list, MAX_SEQ_LENGTH, tokenizer)\n","  print('***** Started training at {} *****'.format(datetime.datetime.now()))\n","  print('  Num examples = {}'.format(len(train_examples)))\n","  print('  Batch size = {}'.format(TRAIN_BATCH_SIZE))\n","  tf.logging.info(\"  Num steps = %d\", num_train_steps)\n","  train_input_fn = run_classifier.input_fn_builder(\n","      features=train_features,\n","      seq_length=MAX_SEQ_LENGTH,\n","      is_training=True,\n","      drop_remainder=True)\n","  estimator.train(input_fn=train_input_fn, max_steps=num_train_steps)\n","  print('***** Finished training at {} *****'.format(datetime.datetime.now()))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Hh8xgb13NU2r","colab_type":"code","outputId":"c98f9b13-6d0c-4805-ed34-a55ab200d310","executionInfo":{"status":"ok","timestamp":1566665381649,"user_tz":-540,"elapsed":320394,"user":{"displayName":"Junha Hyung","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCW-Idc2Xb4naFmTr7ifom9YCmu_ffuOK2Tterv3Q=s64","userId":"06504932993766290160"}},"colab":{"base_uri":"https://localhost:8080/","height":720}},"source":["model_train(estimator)"],"execution_count":16,"outputs":[{"output_type":"stream","text":["W0824 16:45:14.957427 140709399074688 deprecation_wrapper.py:119] From bert_finetune/run_classifier.py:962: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n","\n"],"name":"stderr"},{"output_type":"stream","text":["Please wait...\n","***** Started training at 2019-08-24 16:45:16.425866 *****\n","  Num examples = 8961\n","  Batch size = 32\n"],"name":"stdout"},{"output_type":"stream","text":["W0824 16:45:16.781230 140709399074688 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n","W0824 16:45:20.613144 140709399074688 deprecation_wrapper.py:119] From bert_finetune/modeling.py:171: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n","\n","W0824 16:45:20.618111 140709399074688 deprecation_wrapper.py:119] From bert_finetune/modeling.py:409: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n","\n","W0824 16:45:20.658536 140709399074688 deprecation_wrapper.py:119] From bert_finetune/modeling.py:490: The name tf.assert_less_equal is deprecated. Please use tf.compat.v1.assert_less_equal instead.\n","\n","W0824 16:45:20.710224 140709399074688 deprecation.py:506] From bert_finetune/modeling.py:358: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n","W0824 16:45:20.732504 140709399074688 deprecation.py:323] From bert_finetune/modeling.py:671: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use keras.layers.dense instead.\n","W0824 16:45:24.953074 140709399074688 deprecation_wrapper.py:119] From bert_finetune/run_classifier.py:835: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n","\n","W0824 16:45:26.037561 140709399074688 deprecation_wrapper.py:119] From bert_finetune/optimization.py:27: The name tf.train.get_or_create_global_step is deprecated. Please use tf.compat.v1.train.get_or_create_global_step instead.\n","\n","W0824 16:45:26.040912 140709399074688 deprecation_wrapper.py:119] From bert_finetune/optimization.py:32: The name tf.train.polynomial_decay is deprecated. Please use tf.compat.v1.train.polynomial_decay instead.\n","\n","W0824 16:45:26.057031 140709399074688 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/optimizer_v2/learning_rate_schedule.py:409: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Deprecated in favor of operator or tf.math.divide.\n","W0824 16:45:26.508054 140709399074688 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1205: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","W0824 16:45:39.182979 140709399074688 deprecation_wrapper.py:119] From bert_finetune/run_classifier.py:844: The name tf.train.init_from_checkpoint is deprecated. Please use tf.compat.v1.train.init_from_checkpoint instead.\n","\n","W0824 16:45:41.385489 140709399074688 deprecation_wrapper.py:119] From bert_finetune/run_classifier.py:845: The name tf.train.Scaffold is deprecated. Please use tf.compat.v1.train.Scaffold instead.\n","\n","W0824 16:47:14.521735 140709399074688 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py:741: Variable.load (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Prefer Variable.assign which has equivalent behavior in 2.X.\n"],"name":"stderr"},{"output_type":"stream","text":["***** Finished training at 2019-08-24 16:49:40.989055 *****\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"h2eXFXiBNbH2","colab_type":"code","colab":{}},"source":["def model_eval(estimator):\n","  # Eval the model.\n","  eval_examples = processor.get_dev_examples(TASK_DATA_DIR)\n","  eval_features = run_classifier.convert_examples_to_features(\n","      eval_examples, label_list, MAX_SEQ_LENGTH, tokenizer)\n","  print('***** Started evaluation at {} *****'.format(datetime.datetime.now()))\n","  print('  Num examples = {}'.format(len(eval_examples)))\n","  print('  Batch size = {}'.format(EVAL_BATCH_SIZE))\n","\n","  # Eval will be slightly WRONG on the TPU because it will truncate\n","  # the last batch.\n","  eval_steps = int(len(eval_examples) / EVAL_BATCH_SIZE)\n","  eval_input_fn = run_classifier.input_fn_builder(\n","      features=eval_features,\n","      seq_length=MAX_SEQ_LENGTH,\n","      is_training=False,\n","      drop_remainder=True)\n","  result = estimator.evaluate(input_fn=eval_input_fn, steps=eval_steps)\n","  print('***** Finished evaluation at {} *****'.format(datetime.datetime.now()))\n","  output_eval_file = os.path.join(OUTPUT_DIR, \"eval_results.txt\")\n","  with tf.gfile.GFile(output_eval_file, \"w\") as writer:\n","    print(\"***** Eval results *****\")\n","    for key in sorted(result.keys()):\n","      print('  {} = {}'.format(key, str(result[key])))\n","      writer.write(\"%s = %s\\n\" % (key, str(result[key])))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"YWnoYDZ5ZQp8","colab_type":"code","outputId":"415943f3-8a12-4d14-ead3-47b1e6229849","executionInfo":{"status":"ok","timestamp":1566665453849,"user_tz":-540,"elapsed":392580,"user":{"displayName":"Junha Hyung","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCW-Idc2Xb4naFmTr7ifom9YCmu_ffuOK2Tterv3Q=s64","userId":"06504932993766290160"}},"colab":{"base_uri":"https://localhost:8080/","height":322}},"source":["model_eval(estimator)"],"execution_count":18,"outputs":[{"output_type":"stream","text":["***** Started evaluation at 2019-08-24 16:49:42.031427 *****\n","  Num examples = 2194\n","  Batch size = 8\n"],"name":"stdout"},{"output_type":"stream","text":["W0824 16:49:51.004249 140709399074688 deprecation_wrapper.py:119] From bert_finetune/run_classifier.py:874: The name tf.metrics.accuracy is deprecated. Please use tf.compat.v1.metrics.accuracy instead.\n","\n","W0824 16:49:51.027761 140709399074688 deprecation_wrapper.py:119] From bert_finetune/run_classifier.py:876: The name tf.metrics.mean is deprecated. Please use tf.compat.v1.metrics.mean instead.\n","\n","W0824 16:49:52.644355 140709399074688 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use standard file APIs to check for files with this prefix.\n"],"name":"stderr"},{"output_type":"stream","text":["***** Finished evaluation at 2019-08-24 16:50:52.818571 *****\n","***** Eval results *****\n","  eval_accuracy = 0.609489\n","  eval_loss = 1.2475181\n","  global_step = 840\n","  loss = 1.2838645\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ks1RN4k6ZUiZ","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Vt9QBMeXbcsB","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}