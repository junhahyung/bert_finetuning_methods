{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Bert_fine_tuning.ipynb","version":"0.3.2","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"TPU"},"cells":[{"cell_type":"code","metadata":{"id":"Dm2ZcUlr55EO","colab_type":"code","outputId":"48b4d333-36d2-4dee-b48b-560213989936","executionInfo":{"status":"ok","timestamp":1566522331353,"user_tz":-540,"elapsed":50529,"user":{"displayName":"Junha Hyung","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCW-Idc2Xb4naFmTr7ifom9YCmu_ffuOK2Tterv3Q=s64","userId":"06504932993766290160"}},"colab":{"base_uri":"https://localhost:8080/","height":421}},"source":["import datetime\n","import json\n","import os\n","import pprint\n","import random\n","import string\n","import sys\n","import csv\n","import pandas as pd\n","import tensorflow as tf\n","\n","assert 'COLAB_TPU_ADDR' in os.environ, 'ERROR: Not connected to a TPU runtime; please see the first cell in this notebook for instructions!'\n","TPU_ADDRESS = 'grpc://' + os.environ['COLAB_TPU_ADDR']\n","print('TPU address is', TPU_ADDRESS)\n","\n","from google.colab import auth\n","auth.authenticate_user()\n","with tf.Session(TPU_ADDRESS) as session:\n","  print('TPU devices:')\n","  pprint.pprint(session.list_devices())\n","\n","  # Upload credentials to TPU.\n","  with open('/content/adc.json', 'r') as f:\n","    auth_info = json.load(f)\n","  tf.contrib.cloud.configure_gcs(session, credentials=auth_info)\n","  # Now credentials are set for all future sessions on this TPU."],"execution_count":1,"outputs":[{"output_type":"stream","text":["TPU address is grpc://10.84.116.10:8470\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING: Logging before flag parsing goes to stderr.\n","W0823 01:05:28.809107 140492258375552 lazy_loader.py:50] \n","The TensorFlow contrib module will not be included in TensorFlow 2.0.\n","For more information, please see:\n","  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n","  * https://github.com/tensorflow/addons\n","  * https://github.com/tensorflow/io (for I/O related ops)\n","If you depend on functionality not listed there, please file an issue.\n","\n"],"name":"stderr"},{"output_type":"stream","text":["TPU devices:\n","[_DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:CPU:0, CPU, -1, 17264453172763702357),\n"," _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 3352902676190696243),\n"," _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, 12906206933941431307),\n"," _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, 4312019761890040872),\n"," _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, 12003719367335478604),\n"," _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, 13349362904099686832),\n"," _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 9513597623860807959),\n"," _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, 4587023516144653857),\n"," _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 13771961239067624360),\n"," _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, 7794480189095694761),\n"," _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 8589934592, 9854303479360024120)]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"LmPmHdhf6xj9","colab_type":"code","outputId":"5e389bbf-6672-426b-d3ca-c163e03848c0","executionInfo":{"status":"ok","timestamp":1566522334545,"user_tz":-540,"elapsed":53710,"user":{"displayName":"Junha Hyung","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCW-Idc2Xb4naFmTr7ifom9YCmu_ffuOK2Tterv3Q=s64","userId":"06504932993766290160"}},"colab":{"base_uri":"https://localhost:8080/","height":286}},"source":["import sys\n","from os import listdir\n","!rm -rf bert_finetune\n","!test -d bert_finetune || git clone https://github.com/junhahyung/bert_finetune bert_finetune\n","if not 'bert_finetune' in sys.path:\n","  sys.path += ['bert_finetune']\n","print(listdir(\"bert_finetune\"))\n","# import python modules defined by BERT\n","import modeling\n","import optimization\n","import run_classifier\n","import run_classifier_with_tfhub\n","import tokenization\n","\n","# import tfhub \n","import tensorflow_hub as hub"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Cloning into 'bert_finetune'...\n","remote: Enumerating objects: 74, done.\u001b[K\n","remote: Counting objects: 100% (74/74), done.\u001b[K\n","remote: Compressing objects: 100% (58/58), done.\u001b[K\n","remote: Total 74 (delta 29), reused 39 (delta 11), pack-reused 0\u001b[K\n","Unpacking objects: 100% (74/74), done.\n"],"name":"stdout"},{"output_type":"stream","text":["W0823 01:05:34.308135 140492258375552 deprecation_wrapper.py:119] From bert_finetune/optimization.py:88: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n","\n"],"name":"stderr"},{"output_type":"stream","text":["['run_pretraining.py', 'optimization_test.py', 'modeling_test.py', 'multilingual.md', 'LICENSE', 'extract_features.py', 'run_classifier_with_tfhub.py', 'README.md', '__init__.py', 'predicting_movie_reviews_with_bert_on_tf_hub.ipynb', 'run_squad.py', 'tokenization_test.py', '__init__.pyc', 'modeling.py', 'create_pretraining_data.py', 'run_classifier.py', '.gitignore', 'modeling.pyc', 'requirements.txt', 'sample_text.txt', 'tokenization.py', 'CONTRIBUTING.md', 'optimization.py', '.git']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"61BoPlzHC0bT","colab_type":"code","outputId":"adfbedfa-3f72-4bcf-8df2-1fb413d81d94","executionInfo":{"status":"ok","timestamp":1566522340049,"user_tz":-540,"elapsed":59205,"user":{"displayName":"Junha Hyung","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCW-Idc2Xb4naFmTr7ifom9YCmu_ffuOK2Tterv3Q=s64","userId":"06504932993766290160"}},"colab":{"base_uri":"https://localhost:8080/","height":134}},"source":["TASK = 'korean_sa'\n","assert TASK in ('MRPC', 'CoLA', 'korean_sa'), 'Undefined task'\n","\n","BUCKET = 'mbertfinetune' #@param {type:\"string\"}\n","assert BUCKET, 'Must specify an existing GCS bucket name'\n","TASK_DATA_DIR = 'gs://{}/data/{}'.format(BUCKET, TASK)\n","print('***** Task data directory: {} *****'.format(TASK_DATA_DIR))\n","print(tf.gfile.ListDirectory(TASK_DATA_DIR))\n","OUTPUT_DIR = 'gs://{}/bert-tfhub/models/{}'.format(BUCKET, TASK)\n","tf.gfile.MakeDirs(OUTPUT_DIR)\n","print('***** Model output directory: {} *****'.format(OUTPUT_DIR))\n","\n","BERT_MODEL = 'multi_cased_L-12_H-768_A-12'\n","BERT_MODEL_HUB = 'https://tfhub.dev/google/bert_' + BERT_MODEL + '/1'\n","\n","\"\"\"\n","tdir = os.path.join(TASK_DATA_DIR, \"korean_train.csv\")\n","with tf.gfile.Open(tdir, \"r\") as f:\n","  reader = pd.read_csv(tdir) \n","  lines = []\n","  for line in reader:\n","    lines.append(line)\n","print(lines[18824])\n","\"\"\""],"execution_count":3,"outputs":[{"output_type":"stream","text":["***** Task data directory: gs://mbertfinetune/data/korean_sa *****\n","['korean_dev.csv', 'korean_train.csv']\n","***** Model output directory: gs://mbertfinetune/bert-tfhub/models/korean_sa *****\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["'\\ntdir = os.path.join(TASK_DATA_DIR, \"korean_train.csv\")\\nwith tf.gfile.Open(tdir, \"r\") as f:\\n  reader = pd.read_csv(tdir) \\n  lines = []\\n  for line in reader:\\n    lines.append(line)\\nprint(lines[18824])\\n'"]},"metadata":{"tags":[]},"execution_count":3}]},{"cell_type":"code","metadata":{"id":"_JLqv7pBUiHH","colab_type":"code","outputId":"aef8ea0d-b239-4eb1-b2d8-b77f051f4edb","executionInfo":{"status":"ok","timestamp":1566522356940,"user_tz":-540,"elapsed":76086,"user":{"displayName":"Junha Hyung","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCW-Idc2Xb4naFmTr7ifom9YCmu_ffuOK2Tterv3Q=s64","userId":"06504932993766290160"}},"colab":{"base_uri":"https://localhost:8080/","height":153}},"source":["tokenizer = run_classifier_with_tfhub.create_tokenizer_from_hub_module(BERT_MODEL_HUB)\n","tokenizer.tokenize(\"한국어는 잘 안되는 것 같아요.\")"],"execution_count":4,"outputs":[{"output_type":"stream","text":["W0823 01:05:55.280949 140492258375552 deprecation_wrapper.py:119] From bert_finetune/run_classifier_with_tfhub.py:151: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n","\n","W0823 01:05:55.926263 140492258375552 deprecation_wrapper.py:119] From bert_finetune/tokenization.py:125: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n","\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["['한국', '##어는', '잘', '안', '##되는', '것', '같', '##아', '##요', '.']"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"code","metadata":{"id":"52yngvKU41ha","colab_type":"code","outputId":"a2fe6e46-de31-461d-9f80-f70e1b48a165","executionInfo":{"status":"ok","timestamp":1566522358753,"user_tz":-540,"elapsed":77890,"user":{"displayName":"Junha Hyung","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCW-Idc2Xb4naFmTr7ifom9YCmu_ffuOK2Tterv3Q=s64","userId":"06504932993766290160"}},"colab":{"base_uri":"https://localhost:8080/","height":113}},"source":["TRAIN_BATCH_SIZE = 32\n","EVAL_BATCH_SIZE = 8\n","PREDICT_BATCH_SIZE = 8\n","LEARNING_RATE = 2e-5\n","NUM_TRAIN_EPOCHS = 3\n","MAX_SEQ_LENGTH = 128\n","# Warmup is a period of time where hte learning rate \n","# is small and gradually increases--usually helps training.\n","WARMUP_PROPORTION = 0.1\n","# Model configs\n","SAVE_CHECKPOINTS_STEPS = 1000\n","SAVE_SUMMARY_STEPS = 500\n","layer_wise_lr = (True, 0.3)\n","# layer_wise_lr = None \n","\n","processors = {\n","  \"cola\": run_classifier.ColaProcessor,\n","  \"mnli\": run_classifier.MnliProcessor,\n","  \"mrpc\": run_classifier.MrpcProcessor,\n","  \"korean_sa\": run_classifier.KsaProcessor,\n","}\n","processor = processors[TASK.lower()]()\n","label_list = processor.get_labels()\n","\n","processor.get_train_examples(TASK_DATA_DIR)\n","# Compute number of train and warmup steps from batch size\n","train_examples = processor.get_train_examples(TASK_DATA_DIR)\n","num_train_steps = int(len(train_examples) / TRAIN_BATCH_SIZE * NUM_TRAIN_EPOCHS)\n","num_warmup_steps = int(num_train_steps * WARMUP_PROPORTION)\n","\n","tpu_cluster_resolver = tf.contrib.cluster_resolver.TPUClusterResolver(TPU_ADDRESS)\n","NUM_TPU_CORES = 8\n","ITERATIONS_PER_LOOP = 1000 \n","\n","def get_run_config(output_dir):  \n","  return tf.contrib.tpu.RunConfig(    \n","      cluster=tpu_cluster_resolver,    \n","      model_dir=output_dir,    \n","      save_checkpoints_steps=SAVE_CHECKPOINTS_STEPS,    \n","      tpu_config=tf.contrib.tpu.TPUConfig(        \n","          iterations_per_loop=ITERATIONS_PER_LOOP,        \n","          num_shards=NUM_TPU_CORES,        \n","          per_host_input_for_training=tf.contrib.tpu.InputPipelineConfig.PER_HOST_V2))"],"execution_count":5,"outputs":[{"output_type":"stream","text":["W0823 01:05:56.588287 140492258375552 deprecation_wrapper.py:119] From bert_finetune/run_classifier.py:382: The name tf.gfile.Open is deprecated. Please use tf.io.gfile.GFile instead.\n","\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"ZWIM2qnzMsbH","colab_type":"code","outputId":"1533c505-a2db-4e00-84a1-3b3382ad8e44","executionInfo":{"status":"ok","timestamp":1566522358754,"user_tz":-540,"elapsed":77882,"user":{"displayName":"Junha Hyung","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCW-Idc2Xb4naFmTr7ifom9YCmu_ffuOK2Tterv3Q=s64","userId":"06504932993766290160"}},"colab":{"base_uri":"https://localhost:8080/","height":74}},"source":["os.environ['TFHUB_CACHE_DIR'] = OUTPUT_DIR \n","\n","model_fn = run_classifier_with_tfhub.model_fn_builder(  \n","    num_labels=len(label_list),  \n","    learning_rate=LEARNING_RATE,  \n","    num_train_steps=num_train_steps,  \n","    num_warmup_steps=num_warmup_steps,  \n","    use_tpu=True,  \n","    bert_hub_module_handle=BERT_MODEL_HUB,\n","    layer_wise_lr=layer_wise_lr\n",")\n","\n","estimator_from_tfhub = tf.contrib.tpu.TPUEstimator(\n","  use_tpu=True,\n","  model_fn=model_fn,\n","  config=get_run_config(OUTPUT_DIR),\n","  train_batch_size=TRAIN_BATCH_SIZE,\n","  eval_batch_size=EVAL_BATCH_SIZE,\n","  predict_batch_size=PREDICT_BATCH_SIZE,\n",")"],"execution_count":6,"outputs":[{"output_type":"stream","text":["W0823 01:05:58.425448 140492258375552 estimator.py:1984] Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7fc69765b7b8>) includes params argument, but params are not passed to Estimator.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"6pVcvhIOOyzn","colab_type":"code","colab":{}},"source":["# Train the model\n","def model_train(estimator):\n","  print('Please wait...')\n","  # We'll set sequences to be at most 128 tokens long.\n","  train_features = run_classifier.convert_examples_to_features(\n","      train_examples, label_list, MAX_SEQ_LENGTH, tokenizer)\n","  print('***** Started training at {} *****'.format(datetime.datetime.now()))\n","  print('  Num examples = {}'.format(len(train_examples)))\n","  print('  Batch size = {}'.format(TRAIN_BATCH_SIZE))\n","  tf.logging.info(\"  Num steps = %d\", num_train_steps)\n","  train_input_fn = run_classifier.input_fn_builder(\n","      features=train_features,\n","      seq_length=MAX_SEQ_LENGTH,\n","      is_training=True,\n","      drop_remainder=True)\n","  estimator.train(input_fn=train_input_fn, max_steps=num_train_steps)\n","  print('***** Finished training at {} *****'.format(datetime.datetime.now()))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Hh8xgb13NU2r","colab_type":"code","outputId":"1e55ac96-6f98-4817-f403-8152677bce5e","executionInfo":{"status":"ok","timestamp":1566522668917,"user_tz":-540,"elapsed":388031,"user":{"displayName":"Junha Hyung","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCW-Idc2Xb4naFmTr7ifom9YCmu_ffuOK2Tterv3Q=s64","userId":"06504932993766290160"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["model_train(estimator_from_tfhub)"],"execution_count":8,"outputs":[{"output_type":"stream","text":["W0823 01:05:58.469501 140492258375552 deprecation_wrapper.py:119] From bert_finetune/run_classifier.py:837: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n","\n"],"name":"stderr"},{"output_type":"stream","text":["Please wait...\n","***** Started training at 2019-08-23 01:06:00.554629 *****\n","  Num examples = 8961\n","  Batch size = 32\n"],"name":"stdout"},{"output_type":"stream","text":["W0823 01:06:00.956728 140492258375552 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n","E0823 01:06:57.660384 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/input_ids) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:06:57.663240 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/input_mask) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:06:57.665940 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/segment_ids) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:06:57.672238 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/mlm_positions) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:06:57.680755 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/embeddings/word_embeddings) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:06:57.692126 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/embeddings/token_type_embeddings) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:06:57.701891 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/embeddings/position_embeddings) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:06:57.708843 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/embeddings/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:06:57.712015 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/embeddings/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:06:57.735107 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_0/attention/self/query/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:06:57.738665 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_0/attention/self/query/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:06:57.745330 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_0/attention/self/key/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:06:57.749625 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_0/attention/self/key/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:06:57.756299 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_0/attention/self/value/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:06:57.760103 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_0/attention/self/value/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:06:57.777096 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_0/attention/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:06:57.780848 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_0/attention/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:06:57.790568 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_0/attention/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:06:57.794310 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_0/attention/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:06:57.803243 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_0/intermediate/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:06:57.807874 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_0/intermediate/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:06:57.817381 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_0/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:06:57.821114 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_0/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:06:57.829920 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_0/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:06:57.833108 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_0/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:06:57.845120 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_1/attention/self/query/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:06:57.848837 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_1/attention/self/query/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:06:57.858572 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_1/attention/self/key/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:06:57.861411 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_1/attention/self/key/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:06:57.867473 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_1/attention/self/value/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:06:57.870012 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_1/attention/self/value/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:06:57.885958 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_1/attention/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:06:57.888941 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_1/attention/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:06:57.897896 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_1/attention/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:06:57.902612 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_1/attention/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:06:57.914133 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_1/intermediate/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:06:57.917500 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_1/intermediate/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:06:57.928471 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_1/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:06:57.932027 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_1/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:06:57.942093 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_1/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:06:57.945670 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_1/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:06:57.957192 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_2/attention/self/query/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:06:57.961544 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_2/attention/self/query/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:06:57.968823 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_2/attention/self/key/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:06:57.972213 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_2/attention/self/key/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:06:57.979089 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_2/attention/self/value/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:06:57.981713 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_2/attention/self/value/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:06:57.999986 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_2/attention/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:06:58.003563 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_2/attention/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:06:58.014124 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_2/attention/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:06:58.017112 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_2/attention/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:06:58.026850 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_2/intermediate/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:06:58.030335 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_2/intermediate/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:06:58.041650 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_2/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:06:58.045891 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_2/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:06:58.058575 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_2/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:06:58.061824 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_2/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:06:58.076297 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_3/attention/self/query/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:06:58.080373 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_3/attention/self/query/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:06:58.087210 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_3/attention/self/key/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:06:58.091871 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_3/attention/self/key/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:06:58.097051 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_3/attention/self/value/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:06:58.101120 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_3/attention/self/value/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:06:58.118207 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_3/attention/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:06:58.122117 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_3/attention/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:06:58.132341 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_3/attention/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:06:58.136075 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_3/attention/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:06:58.144618 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_3/intermediate/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:06:58.148795 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_3/intermediate/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:06:58.157471 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_3/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:06:58.161733 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_3/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:06:58.173893 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_3/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:06:58.177393 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_3/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:06:58.190689 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_4/attention/self/query/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:06:58.194046 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_4/attention/self/query/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:06:58.202344 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_4/attention/self/key/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:06:58.205583 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_4/attention/self/key/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:06:58.211448 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_4/attention/self/value/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:06:58.215932 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_4/attention/self/value/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:06:58.233700 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_4/attention/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:06:58.236662 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_4/attention/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:06:58.246543 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_4/attention/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:06:58.249912 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_4/attention/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:06:58.259826 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_4/intermediate/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:06:58.265509 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_4/intermediate/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:06:58.275018 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_4/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:06:58.278767 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_4/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:06:58.289847 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_4/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:06:58.293825 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_4/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:06:58.305485 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_5/attention/self/query/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:06:58.308783 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_5/attention/self/query/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:06:58.316345 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_5/attention/self/key/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:06:58.319435 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_5/attention/self/key/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:06:58.326152 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_5/attention/self/value/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:06:58.329707 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_5/attention/self/value/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:06:58.348370 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_5/attention/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:06:58.353110 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_5/attention/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:06:58.369256 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_5/attention/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:06:58.376858 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_5/attention/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:06:58.387420 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_5/intermediate/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:06:58.391099 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_5/intermediate/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:06:58.402857 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_5/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:06:58.411585 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_5/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:06:58.421022 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_5/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:06:58.424863 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_5/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:06:58.434226 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_6/attention/self/query/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:06:58.437575 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_6/attention/self/query/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:06:58.442914 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_6/attention/self/key/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:06:58.445434 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_6/attention/self/key/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:06:58.450578 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_6/attention/self/value/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:06:58.453791 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_6/attention/self/value/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:06:58.469974 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_6/attention/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:06:58.473401 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_6/attention/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:06:58.483710 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_6/attention/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:06:58.487116 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_6/attention/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:06:58.497477 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_6/intermediate/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:06:58.501094 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_6/intermediate/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:06:58.508742 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_6/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:06:58.512788 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_6/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:06:58.523535 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_6/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:06:58.528411 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_6/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:06:58.540613 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_7/attention/self/query/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:06:58.543814 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_7/attention/self/query/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:06:58.552581 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_7/attention/self/key/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:06:58.555985 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_7/attention/self/key/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:06:58.562570 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_7/attention/self/value/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:06:58.565296 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_7/attention/self/value/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:06:58.581893 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_7/attention/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:06:58.585264 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_7/attention/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:06:58.596856 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_7/attention/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:06:58.600321 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_7/attention/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:06:58.611232 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_7/intermediate/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:06:58.614917 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_7/intermediate/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:06:58.625062 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_7/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:06:58.629499 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_7/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:06:58.638718 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_7/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:06:58.641847 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_7/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:06:58.653445 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_8/attention/self/query/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:06:58.656461 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_8/attention/self/query/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:06:58.663543 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_8/attention/self/key/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:06:58.668398 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_8/attention/self/key/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:06:58.675703 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_8/attention/self/value/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:06:58.679178 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_8/attention/self/value/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:06:58.695703 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_8/attention/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:06:58.699108 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_8/attention/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:06:58.711814 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_8/attention/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:06:58.715205 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_8/attention/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:06:58.725847 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_8/intermediate/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:06:58.731065 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_8/intermediate/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:06:58.740332 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_8/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:06:58.743391 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_8/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:06:58.754040 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_8/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:06:58.757562 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_8/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:06:58.770690 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_9/attention/self/query/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:06:58.774305 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_9/attention/self/query/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:06:58.780704 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_9/attention/self/key/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:06:58.784017 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_9/attention/self/key/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:06:58.789272 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_9/attention/self/value/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:06:58.791611 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_9/attention/self/value/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:06:58.809125 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_9/attention/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:06:58.812933 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_9/attention/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:06:58.822739 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_9/attention/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:06:58.825801 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_9/attention/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:06:58.834904 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_9/intermediate/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:06:58.838613 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_9/intermediate/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:06:58.847304 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_9/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:06:58.850109 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_9/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:06:58.858647 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_9/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:06:58.861854 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_9/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:06:58.873326 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_10/attention/self/query/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:06:58.876095 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_10/attention/self/query/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:06:58.881885 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_10/attention/self/key/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:06:58.885093 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_10/attention/self/key/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:06:58.900295 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_10/attention/self/value/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:06:58.906005 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_10/attention/self/value/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:06:58.924484 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_10/attention/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:06:58.930648 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_10/attention/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:06:58.941093 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_10/attention/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:06:58.948083 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_10/attention/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:06:58.957754 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_10/intermediate/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:06:58.963797 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_10/intermediate/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:06:58.973719 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_10/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:06:58.978888 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_10/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:06:58.989091 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_10/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:06:58.994349 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_10/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:06:59.004225 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_11/attention/self/query/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:06:59.007442 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_11/attention/self/query/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:06:59.013343 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_11/attention/self/key/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:06:59.016222 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_11/attention/self/key/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:06:59.023807 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_11/attention/self/value/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:06:59.026578 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_11/attention/self/value/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:06:59.045449 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_11/attention/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:06:59.048898 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_11/attention/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:06:59.058494 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_11/attention/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:06:59.061453 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_11/attention/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:06:59.069898 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_11/intermediate/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:06:59.073533 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_11/intermediate/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:06:59.082140 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_11/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:06:59.085073 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_11/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:06:59.093119 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_11/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:06:59.096254 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_11/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:06:59.126239 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/pooler/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:06:59.132395 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/pooler/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:06:59.145247 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/cls/predictions/transform/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:06:59.151242 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/cls/predictions/transform/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:06:59.162556 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/cls/predictions/transform/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:06:59.167793 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/cls/predictions/transform/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:06:59.181697 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/cls/predictions/output_bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","W0823 01:06:59.459642 140492258375552 deprecation_wrapper.py:119] From bert_finetune/run_classifier_with_tfhub.py:62: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n","\n","W0823 01:06:59.481919 140492258375552 deprecation_wrapper.py:119] From bert_finetune/run_classifier_with_tfhub.py:69: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n","\n","W0823 01:06:59.483488 140492258375552 deprecation.py:506] From bert_finetune/run_classifier_with_tfhub.py:72: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n","W0823 01:06:59.554388 140492258375552 deprecation_wrapper.py:119] From bert_finetune/optimization.py:27: The name tf.train.get_or_create_global_step is deprecated. Please use tf.compat.v1.train.get_or_create_global_step instead.\n","\n","W0823 01:06:59.559317 140492258375552 deprecation_wrapper.py:119] From bert_finetune/optimization.py:32: The name tf.train.polynomial_decay is deprecated. Please use tf.compat.v1.train.polynomial_decay instead.\n","\n","W0823 01:06:59.578063 140492258375552 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/optimizer_v2/learning_rate_schedule.py:409: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Deprecated in favor of operator or tf.math.divide.\n","W0823 01:06:59.602477 140492258375552 deprecation_wrapper.py:119] From bert_finetune/optimization.py:71: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n","\n","W0823 01:06:59.946028 140492258375552 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1205: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gradients_util.py:93: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n","  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n","W0823 01:08:53.944895 140492258375552 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py:741: Variable.load (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Prefer Variable.assign which has equivalent behavior in 2.X.\n"],"name":"stderr"},{"output_type":"stream","text":["***** Finished training at 2019-08-23 01:11:08.393651 *****\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"h2eXFXiBNbH2","colab_type":"code","colab":{}},"source":["def model_eval(estimator):\n","  # Eval the model.\n","  eval_examples = processor.get_dev_examples(TASK_DATA_DIR)\n","  eval_features = run_classifier.convert_examples_to_features(\n","      eval_examples, label_list, MAX_SEQ_LENGTH, tokenizer)\n","  print('***** Started evaluation at {} *****'.format(datetime.datetime.now()))\n","  print('  Num examples = {}'.format(len(eval_examples)))\n","  print('  Batch size = {}'.format(EVAL_BATCH_SIZE))\n","\n","  # Eval will be slightly WRONG on the TPU because it will truncate\n","  # the last batch.\n","  eval_steps = int(len(eval_examples) / EVAL_BATCH_SIZE)\n","  eval_input_fn = run_classifier.input_fn_builder(\n","      features=eval_features,\n","      seq_length=MAX_SEQ_LENGTH,\n","      is_training=False,\n","      drop_remainder=True)\n","  result = estimator.evaluate(input_fn=eval_input_fn, steps=eval_steps)\n","  print('***** Finished evaluation at {} *****'.format(datetime.datetime.now()))\n","  output_eval_file = os.path.join(OUTPUT_DIR, \"eval_results.txt\")\n","  with tf.gfile.GFile(output_eval_file, \"w\") as writer:\n","    print(\"***** Eval results *****\")\n","    for key in sorted(result.keys()):\n","      print('  {} = {}'.format(key, str(result[key])))\n","      writer.write(\"%s = %s\\n\" % (key, str(result[key])))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"YWnoYDZ5ZQp8","colab_type":"code","outputId":"9570571e-c20b-40ec-a973-f2f87bb578a2","executionInfo":{"status":"ok","timestamp":1566522748147,"user_tz":-540,"elapsed":467245,"user":{"displayName":"Junha Hyung","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCW-Idc2Xb4naFmTr7ifom9YCmu_ffuOK2Tterv3Q=s64","userId":"06504932993766290160"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["model_eval(estimator_from_tfhub)"],"execution_count":10,"outputs":[{"output_type":"stream","text":["***** Started evaluation at 2019-08-23 01:11:09.574261 *****\n","  Num examples = 2194\n","  Batch size = 8\n"],"name":"stdout"},{"output_type":"stream","text":["E0823 01:11:21.593542 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/input_ids) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:11:21.595629 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/input_mask) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:11:21.598205 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/segment_ids) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:11:21.602598 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/mlm_positions) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:11:21.611754 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/embeddings/word_embeddings) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:11:21.626957 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/embeddings/token_type_embeddings) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:11:21.636372 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/embeddings/position_embeddings) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:11:21.643868 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/embeddings/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:11:21.647004 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/embeddings/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:11:21.667424 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_0/attention/self/query/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:11:21.670909 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_0/attention/self/query/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:11:21.680357 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_0/attention/self/key/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:11:21.683806 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_0/attention/self/key/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:11:21.692259 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_0/attention/self/value/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:11:21.695653 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_0/attention/self/value/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:11:21.711397 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_0/attention/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:11:21.714911 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_0/attention/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:11:21.721774 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_0/attention/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:11:21.726611 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_0/attention/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:11:21.736361 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_0/intermediate/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:11:21.740676 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_0/intermediate/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:11:21.751282 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_0/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:11:21.754707 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_0/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:11:21.760982 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_0/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:11:21.764389 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_0/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:11:21.777484 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_1/attention/self/query/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:11:21.780712 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_1/attention/self/query/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:11:21.786538 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_1/attention/self/key/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:11:21.798688 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_1/attention/self/key/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:11:21.808118 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_1/attention/self/value/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:11:21.814221 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_1/attention/self/value/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:11:21.829610 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_1/attention/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:11:21.832745 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_1/attention/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:11:21.838483 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_1/attention/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:11:21.842036 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_1/attention/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:11:21.852302 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_1/intermediate/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:11:21.856274 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_1/intermediate/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:11:21.866739 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_1/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:11:21.870815 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_1/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:11:21.876781 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_1/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:11:21.880567 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_1/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:11:21.893492 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_2/attention/self/query/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:11:21.897043 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_2/attention/self/query/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:11:21.903861 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_2/attention/self/key/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:11:21.908077 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_2/attention/self/key/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:11:21.915842 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_2/attention/self/value/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:11:21.919145 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_2/attention/self/value/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:11:21.934092 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_2/attention/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:11:21.937606 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_2/attention/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:11:21.943687 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_2/attention/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:11:21.947626 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_2/attention/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:11:21.960274 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_2/intermediate/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:11:21.965836 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_2/intermediate/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:11:21.984792 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_2/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:11:21.989479 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_2/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:11:21.995480 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_2/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:11:21.998840 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_2/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:11:22.012009 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_3/attention/self/query/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:11:22.015340 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_3/attention/self/query/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:11:22.023000 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_3/attention/self/key/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:11:22.027734 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_3/attention/self/key/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:11:22.035582 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_3/attention/self/value/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:11:22.038861 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_3/attention/self/value/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:11:22.056623 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_3/attention/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:11:22.060149 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_3/attention/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:11:22.068924 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_3/attention/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:11:22.073338 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_3/attention/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:11:22.083898 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_3/intermediate/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:11:22.089744 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_3/intermediate/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:11:22.099323 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_3/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:11:22.102710 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_3/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:11:22.110813 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_3/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:11:22.114712 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_3/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:11:22.128572 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_4/attention/self/query/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:11:22.132282 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_4/attention/self/query/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:11:22.141523 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_4/attention/self/key/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:11:22.145793 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_4/attention/self/key/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:11:22.154540 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_4/attention/self/value/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:11:22.158089 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_4/attention/self/value/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:11:22.180824 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_4/attention/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:11:22.184260 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_4/attention/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:11:22.194481 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_4/attention/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:11:22.200040 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_4/attention/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:11:22.211495 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_4/intermediate/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:11:22.216261 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_4/intermediate/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:11:22.229346 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_4/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:11:22.233332 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_4/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:11:22.241116 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_4/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:11:22.245081 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_4/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:11:22.258935 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_5/attention/self/query/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:11:22.262477 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_5/attention/self/query/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:11:22.272028 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_5/attention/self/key/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:11:22.278317 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_5/attention/self/key/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:11:22.284609 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_5/attention/self/value/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:11:22.289479 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_5/attention/self/value/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:11:22.305900 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_5/attention/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:11:22.309254 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_5/attention/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:11:22.318742 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_5/attention/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:11:22.322894 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_5/attention/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:11:22.333758 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_5/intermediate/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:11:22.340276 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_5/intermediate/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:11:22.354276 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_5/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:11:22.357831 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_5/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:11:22.366281 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_5/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:11:22.370315 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_5/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:11:22.382135 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_6/attention/self/query/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:11:22.385486 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_6/attention/self/query/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:11:22.395204 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_6/attention/self/key/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:11:22.398914 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_6/attention/self/key/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:11:22.411991 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_6/attention/self/value/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:11:22.416344 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_6/attention/self/value/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:11:22.433458 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_6/attention/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:11:22.437143 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_6/attention/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:11:22.441380 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_6/attention/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:11:22.446822 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_6/attention/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:11:22.461390 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_6/intermediate/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:11:22.467530 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_6/intermediate/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:11:22.478096 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_6/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:11:22.483440 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_6/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:11:22.490845 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_6/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:11:22.493988 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_6/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:11:22.510087 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_7/attention/self/query/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:11:22.514570 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_7/attention/self/query/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:11:22.525013 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_7/attention/self/key/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:11:22.530974 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_7/attention/self/key/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:11:22.539816 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_7/attention/self/value/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:11:22.543497 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_7/attention/self/value/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:11:22.559352 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_7/attention/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:11:22.562854 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_7/attention/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:11:22.573346 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_7/attention/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:11:22.577608 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_7/attention/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:11:22.587637 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_7/intermediate/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:11:22.591723 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_7/intermediate/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:11:22.602278 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_7/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:11:22.605694 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_7/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:11:22.613482 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_7/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:11:22.617215 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_7/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:11:22.631199 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_8/attention/self/query/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:11:22.634642 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_8/attention/self/query/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:11:22.645127 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_8/attention/self/key/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:11:22.650020 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_8/attention/self/key/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:11:22.657870 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_8/attention/self/value/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:11:22.661338 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_8/attention/self/value/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:11:22.676200 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_8/attention/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:11:22.679749 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_8/attention/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:11:22.687477 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_8/attention/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:11:22.691976 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_8/attention/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:11:22.704636 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_8/intermediate/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:11:22.708747 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_8/intermediate/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:11:22.721092 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_8/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:11:22.727745 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_8/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:11:22.735932 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_8/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:11:22.739835 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_8/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:11:22.754700 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_9/attention/self/query/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:11:22.758317 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_9/attention/self/query/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:11:22.768019 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_9/attention/self/key/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:11:22.771567 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_9/attention/self/key/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:11:22.779960 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_9/attention/self/value/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:11:22.783207 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_9/attention/self/value/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:11:22.798382 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_9/attention/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:11:22.801957 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_9/attention/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:11:22.808852 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_9/attention/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:11:22.813628 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_9/attention/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:11:22.825964 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_9/intermediate/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:11:22.829984 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_9/intermediate/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:11:22.841010 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_9/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:11:22.846156 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_9/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:11:22.852542 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_9/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:11:22.856153 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_9/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:11:22.868713 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_10/attention/self/query/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:11:22.873763 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_10/attention/self/query/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:11:22.881383 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_10/attention/self/key/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:11:22.884605 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_10/attention/self/key/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:11:22.893110 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_10/attention/self/value/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:11:22.896478 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_10/attention/self/value/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:11:22.914518 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_10/attention/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:11:22.917960 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_10/attention/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:11:22.925663 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_10/attention/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:11:22.929955 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_10/attention/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:11:22.940700 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_10/intermediate/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:11:22.944783 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_10/intermediate/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:11:22.956620 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_10/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:11:22.960243 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_10/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:11:22.967920 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_10/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:11:22.971287 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_10/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:11:22.983535 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_11/attention/self/query/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:11:22.987191 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_11/attention/self/query/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:11:22.996807 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_11/attention/self/key/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:11:23.000700 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_11/attention/self/key/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:11:23.011547 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_11/attention/self/value/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:11:23.019020 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_11/attention/self/value/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:11:23.035187 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_11/attention/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:11:23.040729 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_11/attention/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:11:23.048734 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_11/attention/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:11:23.051962 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_11/attention/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:11:23.062952 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_11/intermediate/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:11:23.067610 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_11/intermediate/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:11:23.078566 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_11/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:11:23.081995 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_11/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:11:23.090071 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_11/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:11:23.093640 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_11/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:11:23.125821 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/pooler/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:11:23.129352 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/pooler/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:11:23.143726 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/cls/predictions/transform/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:11:23.147197 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/cls/predictions/transform/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:11:23.156871 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/cls/predictions/transform/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:11:23.160690 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/cls/predictions/transform/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","E0823 01:11:23.170800 140492258375552 tpu.py:376] Operation of type Placeholder (module_apply_tokens/cls/predictions/output_bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","W0823 01:11:23.882017 140492258375552 deprecation_wrapper.py:119] From bert_finetune/run_classifier_with_tfhub.py:122: The name tf.metrics.accuracy is deprecated. Please use tf.compat.v1.metrics.accuracy instead.\n","\n","W0823 01:11:23.904511 140492258375552 deprecation_wrapper.py:119] From bert_finetune/run_classifier_with_tfhub.py:123: The name tf.metrics.mean is deprecated. Please use tf.compat.v1.metrics.mean instead.\n","\n","W0823 01:11:25.519690 140492258375552 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use standard file APIs to check for files with this prefix.\n"],"name":"stderr"},{"output_type":"stream","text":["***** Finished evaluation at 2019-08-23 01:12:27.138484 *****\n","***** Eval results *****\n","  eval_accuracy = 0.58804744\n","  eval_loss = 1.1636988\n","  global_step = 840\n","  loss = 1.1987576\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ks1RN4k6ZUiZ","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Vt9QBMeXbcsB","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}