{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Bert_adapter_all_layer.ipynb","version":"0.3.2","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"TPU"},"cells":[{"cell_type":"code","metadata":{"id":"5Frqqj6NBn-z","colab_type":"code","outputId":"2ed66bf1-3d2d-43f7-9cf2-919231954867","executionInfo":{"status":"ok","timestamp":1566666513087,"user_tz":-540,"elapsed":23120,"user":{"displayName":"Junha Hyung","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCW-Idc2Xb4naFmTr7ifom9YCmu_ffuOK2Tterv3Q=s64","userId":"06504932993766290160"}},"colab":{"base_uri":"https://localhost:8080/","height":421}},"source":["import datetime\n","import json\n","import os\n","import pprint\n","import random\n","import string\n","import sys\n","import csv\n","import pandas as pd\n","import tensorflow as tf\n","\n","assert 'COLAB_TPU_ADDR' in os.environ, 'ERROR: Not connected to a TPU runtime; please see the first cell in this notebook for instructions!'\n","TPU_ADDRESS = 'grpc://' + os.environ['COLAB_TPU_ADDR']\n","print('TPU address is', TPU_ADDRESS)\n","\n","from google.colab import auth\n","auth.authenticate_user()\n","with tf.Session(TPU_ADDRESS) as session:\n","  print('TPU devices:')\n","  pprint.pprint(session.list_devices())\n","\n","  # Upload credentials to TPU.\n","  with open('/content/adc.json', 'r') as f:\n","    auth_info = json.load(f)\n","  tf.contrib.cloud.configure_gcs(session, credentials=auth_info)\n","  # Now credentials are set for all future sessions on this TPU."],"execution_count":1,"outputs":[{"output_type":"stream","text":["TPU address is grpc://10.84.231.154:8470\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING: Logging before flag parsing goes to stderr.\n","W0824 17:08:30.385006 140042744510336 lazy_loader.py:50] \n","The TensorFlow contrib module will not be included in TensorFlow 2.0.\n","For more information, please see:\n","  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n","  * https://github.com/tensorflow/addons\n","  * https://github.com/tensorflow/io (for I/O related ops)\n","If you depend on functionality not listed there, please file an issue.\n","\n"],"name":"stderr"},{"output_type":"stream","text":["TPU devices:\n","[_DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:CPU:0, CPU, -1, 5161697567607345077),\n"," _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 15013514628316835704),\n"," _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, 14331371067235975315),\n"," _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, 17970072412034988948),\n"," _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, 13639913727209356923),\n"," _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, 15016154012244499900),\n"," _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 10601350430831536356),\n"," _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, 4545879471716091328),\n"," _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 2234474461560175557),\n"," _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, 8308303746263012466),\n"," _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 8589934592, 238495807045503986)]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"fTVq31UdB8YC","colab_type":"code","outputId":"b592fdc5-1d66-462c-e2ac-073d2605fce9","executionInfo":{"status":"ok","timestamp":1566666517294,"user_tz":-540,"elapsed":27317,"user":{"displayName":"Junha Hyung","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCW-Idc2Xb4naFmTr7ifom9YCmu_ffuOK2Tterv3Q=s64","userId":"06504932993766290160"}},"colab":{"base_uri":"https://localhost:8080/","height":306}},"source":["import sys\n","from os import listdir\n","!rm -rf bert_finetune\n","!test -d bert_adapter || git clone https://github.com/junhahyung/adapter-bert bert_adapter\n","if not 'bert_adapter' in sys.path:\n","  sys.path += ['bert_adapter']\n","print(listdir(\"bert_adapter\"))\n","# import python modules defined by BERT\n","import modeling\n","import optimization\n","import run_classifier\n","import run_classifier_with_tfhub\n","import tokenization\n","\n","# import tfhub \n","import tensorflow_hub as hub"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Cloning into 'bert_adapter'...\n","remote: Enumerating objects: 47, done.\u001b[K\n","remote: Counting objects: 100% (47/47), done.\u001b[K\n","remote: Compressing objects: 100% (35/35), done.\u001b[K\n","remote: Total 47 (delta 16), reused 36 (delta 8), pack-reused 0\u001b[K\n","Unpacking objects: 100% (47/47), done.\n"],"name":"stdout"},{"output_type":"stream","text":["W0824 17:08:37.002433 140042744510336 deprecation_wrapper.py:119] From bert_adapter/optimization.py:90: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n","\n"],"name":"stderr"},{"output_type":"stream","text":["['run_classifier.py', 'optimization_test.py', 'modeling_test.py', 'LICENSE', 'optimization.py', '__init__.py', 'run_classifier_with_tfhub.py', 'tokenization.py', 'README.md', 'modeling.py', 'requirements.txt', 'tokenization_test.py', '.git']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"CPmUEVCOClaX","colab_type":"code","outputId":"3a47709d-03d1-4995-d926-c2d8f9cead9d","executionInfo":{"status":"ok","timestamp":1566666522800,"user_tz":-540,"elapsed":32816,"user":{"displayName":"Junha Hyung","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCW-Idc2Xb4naFmTr7ifom9YCmu_ffuOK2Tterv3Q=s64","userId":"06504932993766290160"}},"colab":{"base_uri":"https://localhost:8080/","height":134}},"source":["TASK = 'korean_sa'\n","assert TASK in ('MRPC', 'CoLA', 'korean_sa'), 'Undefined task'\n","\n","BUCKET = 'mbertfinetune' #@param {type:\"string\"}\n","assert BUCKET, 'Must specify an existing GCS bucket name'\n","TASK_DATA_DIR = 'gs://{}/data/{}'.format(BUCKET, TASK)\n","print('***** Task data directory: {} *****'.format(TASK_DATA_DIR))\n","print(tf.gfile.ListDirectory(TASK_DATA_DIR))\n","OUTPUT_DIR = 'gs://{}/bert-adapter-tfhub-all_layers/models/{}'.format(BUCKET, TASK)\n","tf.gfile.MakeDirs(OUTPUT_DIR)\n","print('***** Model output directory: {} *****'.format(OUTPUT_DIR))\n","\n","BERT_MODEL = 'multi_cased_L-12_H-768_A-12'\n","BERT_MODEL_HUB = 'https://tfhub.dev/google/bert_' + BERT_MODEL + '/1'\n","\n","CKPT_DIR = 'gs://{}/{}/bert_model.ckpt'.format(BUCKET, BERT_MODEL)\n","CONFIG_DIR = 'gs://{}/{}/bert_config.json'.format(BUCKET, BERT_MODEL)"],"execution_count":3,"outputs":[{"output_type":"stream","text":["***** Task data directory: gs://mbertfinetune/data/korean_sa *****\n","['korean_dev.csv', 'korean_train.csv']\n","***** Model output directory: gs://mbertfinetune/bert-adapter-tfhub-all_layers/models/korean_sa *****\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"TBjQWk3YFRh7","colab_type":"code","outputId":"717fa965-e87c-476e-813f-1173ebc4bfa3","executionInfo":{"status":"ok","timestamp":1566666536901,"user_tz":-540,"elapsed":46909,"user":{"displayName":"Junha Hyung","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCW-Idc2Xb4naFmTr7ifom9YCmu_ffuOK2Tterv3Q=s64","userId":"06504932993766290160"}},"colab":{"base_uri":"https://localhost:8080/","height":153}},"source":["tokenizer = run_classifier_with_tfhub.create_tokenizer_from_hub_module(BERT_MODEL_HUB)\n","tokenizer.tokenize(\"한국어는 잘 안되는 것 같아요.\")"],"execution_count":4,"outputs":[{"output_type":"stream","text":["W0824 17:08:55.822245 140042744510336 deprecation_wrapper.py:119] From bert_adapter/run_classifier_with_tfhub.py:151: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n","\n","W0824 17:08:56.167306 140042744510336 deprecation_wrapper.py:119] From bert_adapter/tokenization.py:125: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n","\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["['한국', '##어는', '잘', '안', '##되는', '것', '같', '##아', '##요', '.']"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"code","metadata":{"id":"BCKVMv4zF83k","colab_type":"code","outputId":"2c60d5ff-1dfa-45d5-d7e4-bb8e2dc7ca64","executionInfo":{"status":"ok","timestamp":1566666540197,"user_tz":-540,"elapsed":50198,"user":{"displayName":"Junha Hyung","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCW-Idc2Xb4naFmTr7ifom9YCmu_ffuOK2Tterv3Q=s64","userId":"06504932993766290160"}},"colab":{"base_uri":"https://localhost:8080/","height":113}},"source":["TRAIN_BATCH_SIZE = 32\n","EVAL_BATCH_SIZE = 8\n","PREDICT_BATCH_SIZE = 8\n","LEARNING_RATE = 3e-4 \n","NUM_TRAIN_EPOCHS = 3 \n","MAX_SEQ_LENGTH = 128\n","# Warmup is a period of time where hte learning rate \n","# is small and gradually increases--usually helps training.\n","WARMUP_PROPORTION = 0.1\n","# Model configs\n","SAVE_CHECKPOINTS_STEPS = 1000\n","SAVE_SUMMARY_STEPS = 500\n","# layer_wise_lr = (True, 0.3)\n","# layer_wise_lr = None \n","\n","processors = {\n","  \"cola\": run_classifier.ColaProcessor,\n","  \"mnli\": run_classifier.MnliProcessor,\n","  \"mrpc\": run_classifier.MrpcProcessor,\n","  \"korean_sa\": run_classifier.KsaProcessor,\n","}\n","processor = processors[TASK.lower()]()\n","label_list = processor.get_labels()\n","\n","processor.get_train_examples(TASK_DATA_DIR)\n","# Compute number of train and warmup steps from batch size\n","train_examples = processor.get_train_examples(TASK_DATA_DIR)\n","num_train_steps = int(len(train_examples) / TRAIN_BATCH_SIZE * NUM_TRAIN_EPOCHS)\n","num_warmup_steps = int(num_train_steps * WARMUP_PROPORTION)\n","\n","tpu_cluster_resolver = tf.contrib.cluster_resolver.TPUClusterResolver(TPU_ADDRESS)\n","NUM_TPU_CORES = 8\n","ITERATIONS_PER_LOOP = 1000 \n","\n","def get_run_config(output_dir):  \n","  return tf.contrib.tpu.RunConfig(    \n","      cluster=tpu_cluster_resolver,    \n","      model_dir=output_dir,    \n","      save_checkpoints_steps=SAVE_CHECKPOINTS_STEPS,    \n","      tpu_config=tf.contrib.tpu.TPUConfig(        \n","          iterations_per_loop=ITERATIONS_PER_LOOP,        \n","          num_shards=NUM_TPU_CORES,        \n","          per_host_input_for_training=tf.contrib.tpu.InputPipelineConfig.PER_HOST_V2))"],"execution_count":5,"outputs":[{"output_type":"stream","text":["W0824 17:08:56.588099 140042744510336 deprecation_wrapper.py:119] From bert_adapter/run_classifier.py:334: The name tf.gfile.Open is deprecated. Please use tf.io.gfile.GFile instead.\n","\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"871TbmKAJF_u","colab_type":"code","outputId":"87865271-c591-4773-9c23-d7b4c229b5f5","executionInfo":{"status":"ok","timestamp":1566666540735,"user_tz":-540,"elapsed":50728,"user":{"displayName":"Junha Hyung","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCW-Idc2Xb4naFmTr7ifom9YCmu_ffuOK2Tterv3Q=s64","userId":"06504932993766290160"}},"colab":{"base_uri":"https://localhost:8080/","height":74}},"source":["# Maybe don't need this because I'm not using TFHUB\n","# os.environ['TFHUB_CACHE_DIR'] = OUTPUT_DIR\n","bert_config = modeling.BertConfig.from_json_file(CONFIG_DIR)\n","\n","model_fn = run_classifier.model_fn_builder(\n","    bert_config=bert_config,\n","    num_labels=len(label_list),\n","    init_checkpoint=CKPT_DIR,\n","    learning_rate=LEARNING_RATE,\n","    num_train_steps=num_train_steps,\n","    num_warmup_steps=num_warmup_steps,\n","    use_tpu=True,\n","    use_one_hot_embeddings=True,\n","    use_all_layers=True\n","     )\n","# use_one_hot_embeddings is set as same value as use_tpu\n","\n","estimator = tf.contrib.tpu.TPUEstimator(\n","  use_tpu=True,\n","  model_fn=model_fn,\n","  config=get_run_config(OUTPUT_DIR),\n","  train_batch_size=TRAIN_BATCH_SIZE,\n","  eval_batch_size=EVAL_BATCH_SIZE,\n","  predict_batch_size=PREDICT_BATCH_SIZE,\n",")"],"execution_count":6,"outputs":[{"output_type":"stream","text":["W0824 17:09:00.173160 140042744510336 estimator.py:1984] Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7f5dee47ab70>) includes params argument, but params are not passed to Estimator.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"QOdr4s4wbG9S","colab_type":"code","colab":{}},"source":["def model_train(estimator):\n","  print('Please wait...')\n","  # We'll set sequences to be at most 128 tokens long.\n","  train_features = run_classifier.convert_examples_to_features(\n","      train_examples, label_list, MAX_SEQ_LENGTH, tokenizer)\n","  print('***** Started training at {} *****'.format(datetime.datetime.now()))\n","  print('  Num examples = {}'.format(len(train_examples)))\n","  print('  Batch size = {}'.format(TRAIN_BATCH_SIZE))\n","  tf.logging.info(\"  Num steps = %d\", num_train_steps)\n","  train_input_fn = run_classifier.input_fn_builder(\n","      features=train_features,\n","      seq_length=MAX_SEQ_LENGTH,\n","      is_training=True,\n","      drop_remainder=True)\n","  estimator.train(input_fn=train_input_fn, max_steps=num_train_steps)\n","  print('***** Finished training at {} *****'.format(datetime.datetime.now()))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"uuisjVAKjLfI","colab_type":"code","outputId":"1ca96f6f-c74d-489b-9a9e-6d04c779ef9e","executionInfo":{"status":"ok","timestamp":1566666730896,"user_tz":-540,"elapsed":240879,"user":{"displayName":"Junha Hyung","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCW-Idc2Xb4naFmTr7ifom9YCmu_ffuOK2Tterv3Q=s64","userId":"06504932993766290160"}},"colab":{"base_uri":"https://localhost:8080/","height":740}},"source":["model_train(estimator)"],"execution_count":8,"outputs":[{"output_type":"stream","text":["W0824 17:09:00.203823 140042744510336 deprecation_wrapper.py:119] From bert_adapter/run_classifier.py:916: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n","\n"],"name":"stderr"},{"output_type":"stream","text":["Please wait...\n","***** Started training at 2019-08-24 17:09:01.629659 *****\n","  Num examples = 8961\n","  Batch size = 32\n"],"name":"stdout"},{"output_type":"stream","text":["W0824 17:09:02.005680 140042744510336 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n","W0824 17:09:05.837388 140042744510336 deprecation_wrapper.py:119] From bert_adapter/modeling.py:174: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n","\n","W0824 17:09:05.842920 140042744510336 deprecation_wrapper.py:119] From bert_adapter/modeling.py:487: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n","\n","W0824 17:09:05.878098 140042744510336 deprecation_wrapper.py:119] From bert_adapter/modeling.py:568: The name tf.assert_less_equal is deprecated. Please use tf.compat.v1.assert_less_equal instead.\n","\n","W0824 17:09:05.903556 140042744510336 deprecation_wrapper.py:119] From bert_adapter/modeling.py:443: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n","\n","W0824 17:09:05.928837 140042744510336 deprecation.py:506] From bert_adapter/modeling.py:435: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n","W0824 17:09:05.948580 140042744510336 deprecation.py:323] From bert_adapter/modeling.py:749: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use keras.layers.dense instead.\n","W0824 17:09:12.485619 140042744510336 deprecation_wrapper.py:119] From bert_adapter/optimization.py:27: The name tf.train.get_or_create_global_step is deprecated. Please use tf.compat.v1.train.get_or_create_global_step instead.\n","\n","W0824 17:09:12.488497 140042744510336 deprecation_wrapper.py:119] From bert_adapter/optimization.py:32: The name tf.train.polynomial_decay is deprecated. Please use tf.compat.v1.train.polynomial_decay instead.\n","\n","W0824 17:09:12.499490 140042744510336 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/optimizer_v2/learning_rate_schedule.py:409: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Deprecated in favor of operator or tf.math.divide.\n","W0824 17:09:12.908383 140042744510336 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1205: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","W0824 17:09:24.308084 140042744510336 deprecation_wrapper.py:119] From bert_adapter/run_classifier.py:798: The name tf.train.init_from_checkpoint is deprecated. Please use tf.compat.v1.train.init_from_checkpoint instead.\n","\n","W0824 17:09:26.017757 140042744510336 deprecation_wrapper.py:119] From bert_adapter/run_classifier.py:799: The name tf.train.Scaffold is deprecated. Please use tf.compat.v1.train.Scaffold instead.\n","\n","W0824 17:10:38.361217 140042744510336 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py:741: Variable.load (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Prefer Variable.assign which has equivalent behavior in 2.X.\n"],"name":"stderr"},{"output_type":"stream","text":["***** Finished training at 2019-08-24 17:12:10.358515 *****\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"d67eZ9kojOA3","colab_type":"code","colab":{}},"source":["def model_eval(estimator):\n","  # Eval the model.\n","  eval_examples = processor.get_dev_examples(TASK_DATA_DIR)\n","  eval_features = run_classifier.convert_examples_to_features(\n","      eval_examples, label_list, MAX_SEQ_LENGTH, tokenizer)\n","  print('***** Started evaluation at {} *****'.format(datetime.datetime.now()))\n","  print('  Num examples = {}'.format(len(eval_examples)))\n","  print('  Batch size = {}'.format(EVAL_BATCH_SIZE))\n","\n","  # Eval will be slightly WRONG on the TPU because it will truncate\n","  # the last batch.\n","  eval_steps = int(len(eval_examples) / EVAL_BATCH_SIZE)\n","  eval_input_fn = run_classifier.input_fn_builder(\n","      features=eval_features,\n","      seq_length=MAX_SEQ_LENGTH,\n","      is_training=False,\n","      drop_remainder=True)\n","  result = estimator.evaluate(input_fn=eval_input_fn, steps=eval_steps)\n","  print('***** Finished evaluation at {} *****'.format(datetime.datetime.now()))\n","  output_eval_file = os.path.join(OUTPUT_DIR, \"eval_results.txt\")\n","  with tf.gfile.GFile(output_eval_file, \"w\") as writer:\n","    print(\"***** Eval results *****\")\n","    for key in sorted(result.keys()):\n","      print('  {} = {}'.format(key, str(result[key])))\n","      writer.write(\"%s = %s\\n\" % (key, str(result[key])))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"rBL1bpJAnV56","colab_type":"code","outputId":"148b4a5b-fb42-48e9-bfe9-243f08a4912d","executionInfo":{"status":"ok","timestamp":1566666787428,"user_tz":-540,"elapsed":297401,"user":{"displayName":"Junha Hyung","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCW-Idc2Xb4naFmTr7ifom9YCmu_ffuOK2Tterv3Q=s64","userId":"06504932993766290160"}},"colab":{"base_uri":"https://localhost:8080/","height":322}},"source":["model_eval(estimator)"],"execution_count":10,"outputs":[{"output_type":"stream","text":["***** Started evaluation at 2019-08-24 17:12:11.709460 *****\n","  Num examples = 2194\n","  Batch size = 8\n"],"name":"stdout"},{"output_type":"stream","text":["W0824 17:12:20.720178 140042744510336 deprecation_wrapper.py:119] From bert_adapter/run_classifier.py:828: The name tf.metrics.accuracy is deprecated. Please use tf.compat.v1.metrics.accuracy instead.\n","\n","W0824 17:12:20.741233 140042744510336 deprecation_wrapper.py:119] From bert_adapter/run_classifier.py:830: The name tf.metrics.mean is deprecated. Please use tf.compat.v1.metrics.mean instead.\n","\n","W0824 17:12:22.759567 140042744510336 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use standard file APIs to check for files with this prefix.\n"],"name":"stderr"},{"output_type":"stream","text":["***** Finished evaluation at 2019-08-24 17:13:06.446557 *****\n","***** Eval results *****\n","  eval_accuracy = 0.58987224\n","  eval_loss = 1.0864862\n","  global_step = 840\n","  loss = 1.1014642\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"58CBESPGqUAn","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}