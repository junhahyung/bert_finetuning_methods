{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Bert_adapter.ipynb","version":"0.3.2","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"TPU"},"cells":[{"cell_type":"code","metadata":{"id":"5Frqqj6NBn-z","colab_type":"code","outputId":"0ad38387-df54-4ea7-ce40-e9cd2c2fa27e","executionInfo":{"status":"ok","timestamp":1566575438196,"user_tz":-540,"elapsed":60402,"user":{"displayName":"Junha Hyung","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCW-Idc2Xb4naFmTr7ifom9YCmu_ffuOK2Tterv3Q=s64","userId":"06504932993766290160"}},"colab":{"base_uri":"https://localhost:8080/","height":421}},"source":["import datetime\n","import json\n","import os\n","import pprint\n","import random\n","import string\n","import sys\n","import csv\n","import pandas as pd\n","import tensorflow as tf\n","\n","assert 'COLAB_TPU_ADDR' in os.environ, 'ERROR: Not connected to a TPU runtime; please see the first cell in this notebook for instructions!'\n","TPU_ADDRESS = 'grpc://' + os.environ['COLAB_TPU_ADDR']\n","print('TPU address is', TPU_ADDRESS)\n","\n","from google.colab import auth\n","auth.authenticate_user()\n","with tf.Session(TPU_ADDRESS) as session:\n","  print('TPU devices:')\n","  pprint.pprint(session.list_devices())\n","\n","  # Upload credentials to TPU.\n","  with open('/content/adc.json', 'r') as f:\n","    auth_info = json.load(f)\n","  tf.contrib.cloud.configure_gcs(session, credentials=auth_info)\n","  # Now credentials are set for all future sessions on this TPU."],"execution_count":1,"outputs":[{"output_type":"stream","text":["TPU address is grpc://10.28.204.202:8470\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING: Logging before flag parsing goes to stderr.\n","W0823 15:50:35.634482 140651498272640 lazy_loader.py:50] \n","The TensorFlow contrib module will not be included in TensorFlow 2.0.\n","For more information, please see:\n","  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n","  * https://github.com/tensorflow/addons\n","  * https://github.com/tensorflow/io (for I/O related ops)\n","If you depend on functionality not listed there, please file an issue.\n","\n"],"name":"stderr"},{"output_type":"stream","text":["TPU devices:\n","[_DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:CPU:0, CPU, -1, 13482303892080811834),\n"," _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 2515585708374273571),\n"," _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, 4595646160572921696),\n"," _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, 16396042277660556107),\n"," _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, 3163037380970760156),\n"," _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, 15592275262159107189),\n"," _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 15544886151471905964),\n"," _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, 5466859031700314521),\n"," _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 3746649068138925329),\n"," _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, 14506477853194268901),\n"," _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 8589934592, 4135844519127922490)]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"fTVq31UdB8YC","colab_type":"code","outputId":"71ae3a71-fdad-48ee-ce4a-c83e628cde5e","executionInfo":{"status":"ok","timestamp":1566575441369,"user_tz":-540,"elapsed":63562,"user":{"displayName":"Junha Hyung","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCW-Idc2Xb4naFmTr7ifom9YCmu_ffuOK2Tterv3Q=s64","userId":"06504932993766290160"}},"colab":{"base_uri":"https://localhost:8080/","height":306}},"source":["import sys\n","from os import listdir\n","!rm -rf bert_finetune\n","!test -d bert_adapter || git clone https://github.com/junhahyung/adapter-bert bert_adapter\n","if not 'bert_adapter' in sys.path:\n","  sys.path += ['bert_adapter']\n","print(listdir(\"bert_adapter\"))\n","# import python modules defined by BERT\n","import modeling\n","import optimization\n","import run_classifier\n","import run_classifier_with_tfhub\n","import tokenization\n","\n","# import tfhub \n","import tensorflow_hub as hub"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Cloning into 'bert_adapter'...\n","remote: Enumerating objects: 41, done.\u001b[K\n","remote: Counting objects: 100% (41/41), done.\u001b[K\n","remote: Compressing objects: 100% (31/31), done.\u001b[K\n","remote: Total 41 (delta 12), reused 32 (delta 6), pack-reused 0\u001b[K\n","Unpacking objects: 100% (41/41), done.\n"],"name":"stdout"},{"output_type":"stream","text":["W0823 15:50:40.976601 140651498272640 deprecation_wrapper.py:119] From bert_adapter/optimization.py:90: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n","\n"],"name":"stderr"},{"output_type":"stream","text":["['optimization_test.py', 'modeling_test.py', 'LICENSE', 'run_classifier_with_tfhub.py', 'README.md', '__init__.py', 'tokenization_test.py', 'modeling.py', 'run_classifier.py', 'requirements.txt', 'tokenization.py', 'optimization.py', '.git']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"CPmUEVCOClaX","colab_type":"code","outputId":"9d423417-7b1d-417b-e6ea-bf6f0cd89e35","executionInfo":{"status":"ok","timestamp":1566575446908,"user_tz":-540,"elapsed":69092,"user":{"displayName":"Junha Hyung","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCW-Idc2Xb4naFmTr7ifom9YCmu_ffuOK2Tterv3Q=s64","userId":"06504932993766290160"}},"colab":{"base_uri":"https://localhost:8080/","height":134}},"source":["TASK = 'korean_sa'\n","assert TASK in ('MRPC', 'CoLA', 'korean_sa'), 'Undefined task'\n","\n","BUCKET = 'mbertfinetune' #@param {type:\"string\"}\n","assert BUCKET, 'Must specify an existing GCS bucket name'\n","TASK_DATA_DIR = 'gs://{}/data/{}'.format(BUCKET, TASK)\n","print('***** Task data directory: {} *****'.format(TASK_DATA_DIR))\n","print(tf.gfile.ListDirectory(TASK_DATA_DIR))\n","OUTPUT_DIR = 'gs://{}/bert-adapter-tfhub/models/{}'.format(BUCKET, TASK)\n","tf.gfile.MakeDirs(OUTPUT_DIR)\n","print('***** Model output directory: {} *****'.format(OUTPUT_DIR))\n","\n","BERT_MODEL = 'multi_cased_L-12_H-768_A-12'\n","BERT_MODEL_HUB = 'https://tfhub.dev/google/bert_' + BERT_MODEL + '/1'\n","\n","CKPT_DIR = 'gs://{}/{}/bert_model.ckpt'.format(BUCKET, BERT_MODEL)\n","CONFIG_DIR = 'gs://{}/{}/bert_config.json'.format(BUCKET, BERT_MODEL)"],"execution_count":3,"outputs":[{"output_type":"stream","text":["***** Task data directory: gs://mbertfinetune/data/korean_sa *****\n","['korean_dev.csv', 'korean_train.csv']\n","***** Model output directory: gs://mbertfinetune/bert-adapter-tfhub/models/korean_sa *****\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"TBjQWk3YFRh7","colab_type":"code","outputId":"41515089-2a36-4190-9565-c34fae5305ed","executionInfo":{"status":"ok","timestamp":1566575462143,"user_tz":-540,"elapsed":84318,"user":{"displayName":"Junha Hyung","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCW-Idc2Xb4naFmTr7ifom9YCmu_ffuOK2Tterv3Q=s64","userId":"06504932993766290160"}},"colab":{"base_uri":"https://localhost:8080/","height":153}},"source":["tokenizer = run_classifier_with_tfhub.create_tokenizer_from_hub_module(BERT_MODEL_HUB)\n","tokenizer.tokenize(\"한국어는 잘 안되는 것 같아요.\")"],"execution_count":4,"outputs":[{"output_type":"stream","text":["W0823 15:51:00.851563 140651498272640 deprecation_wrapper.py:119] From bert_adapter/run_classifier_with_tfhub.py:151: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n","\n","W0823 15:51:01.322199 140651498272640 deprecation_wrapper.py:119] From bert_adapter/tokenization.py:125: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n","\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["['한국', '##어는', '잘', '안', '##되는', '것', '같', '##아', '##요', '.']"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"code","metadata":{"id":"BCKVMv4zF83k","colab_type":"code","outputId":"97a3b8fc-f9c3-485d-d959-6cff68bc3658","executionInfo":{"status":"ok","timestamp":1566575464101,"user_tz":-540,"elapsed":86268,"user":{"displayName":"Junha Hyung","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCW-Idc2Xb4naFmTr7ifom9YCmu_ffuOK2Tterv3Q=s64","userId":"06504932993766290160"}},"colab":{"base_uri":"https://localhost:8080/","height":113}},"source":["TRAIN_BATCH_SIZE = 32\n","EVAL_BATCH_SIZE = 8\n","PREDICT_BATCH_SIZE = 8\n","LEARNING_RATE = 3e-4 \n","NUM_TRAIN_EPOCHS = 3 \n","MAX_SEQ_LENGTH = 128\n","# Warmup is a period of time where hte learning rate \n","# is small and gradually increases--usually helps training.\n","WARMUP_PROPORTION = 0.1\n","# Model configs\n","SAVE_CHECKPOINTS_STEPS = 1000\n","SAVE_SUMMARY_STEPS = 500\n","# layer_wise_lr = (True, 0.3)\n","# layer_wise_lr = None \n","\n","processors = {\n","  \"cola\": run_classifier.ColaProcessor,\n","  \"mnli\": run_classifier.MnliProcessor,\n","  \"mrpc\": run_classifier.MrpcProcessor,\n","  \"korean_sa\": run_classifier.KsaProcessor,\n","}\n","processor = processors[TASK.lower()]()\n","label_list = processor.get_labels()\n","\n","processor.get_train_examples(TASK_DATA_DIR)\n","# Compute number of train and warmup steps from batch size\n","train_examples = processor.get_train_examples(TASK_DATA_DIR)\n","num_train_steps = int(len(train_examples) / TRAIN_BATCH_SIZE * NUM_TRAIN_EPOCHS)\n","num_warmup_steps = int(num_train_steps * WARMUP_PROPORTION)\n","\n","tpu_cluster_resolver = tf.contrib.cluster_resolver.TPUClusterResolver(TPU_ADDRESS)\n","NUM_TPU_CORES = 8\n","ITERATIONS_PER_LOOP = 1000 \n","\n","def get_run_config(output_dir):  \n","  return tf.contrib.tpu.RunConfig(    \n","      cluster=tpu_cluster_resolver,    \n","      model_dir=output_dir,    \n","      save_checkpoints_steps=SAVE_CHECKPOINTS_STEPS,    \n","      tpu_config=tf.contrib.tpu.TPUConfig(        \n","          iterations_per_loop=ITERATIONS_PER_LOOP,        \n","          num_shards=NUM_TPU_CORES,        \n","          per_host_input_for_training=tf.contrib.tpu.InputPipelineConfig.PER_HOST_V2))"],"execution_count":5,"outputs":[{"output_type":"stream","text":["W0823 15:51:01.905767 140651498272640 deprecation_wrapper.py:119] From bert_adapter/run_classifier.py:334: The name tf.gfile.Open is deprecated. Please use tf.io.gfile.GFile instead.\n","\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"871TbmKAJF_u","colab_type":"code","outputId":"1d698f0a-e02f-4abf-fc82-3d24bb62a208","executionInfo":{"status":"ok","timestamp":1566575464820,"user_tz":-540,"elapsed":86980,"user":{"displayName":"Junha Hyung","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCW-Idc2Xb4naFmTr7ifom9YCmu_ffuOK2Tterv3Q=s64","userId":"06504932993766290160"}},"colab":{"base_uri":"https://localhost:8080/","height":94}},"source":["# Maybe don't need this because I'm not using TFHUB\n","# os.environ['TFHUB_CACHE_DIR'] = OUTPUT_DIR\n","bert_config = modeling.BertConfig.from_json_file(CONFIG_DIR)\n","\n","model_fn = run_classifier.model_fn_builder(\n","    bert_config=bert_config,\n","    num_labels=len(label_list),\n","    init_checkpoint=CKPT_DIR,\n","    learning_rate=LEARNING_RATE,\n","    num_train_steps=num_train_steps,\n","    num_warmup_steps=num_warmup_steps,\n","    use_tpu=True,\n","    use_one_hot_embeddings=True\n","     )\n","# use_one_hot_embeddings is set as same value as use_tpu\n","\n","estimator = tf.contrib.tpu.TPUEstimator(\n","  use_tpu=True,\n","  model_fn=model_fn,\n","  config=get_run_config(OUTPUT_DIR),\n","  train_batch_size=TRAIN_BATCH_SIZE,\n","  eval_batch_size=EVAL_BATCH_SIZE,\n","  predict_batch_size=PREDICT_BATCH_SIZE,\n",")"],"execution_count":6,"outputs":[{"output_type":"stream","text":["W0823 15:51:04.463958 140651498272640 estimator.py:1984] Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7febaad4a6a8>) includes params argument, but params are not passed to Estimator.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"QOdr4s4wbG9S","colab_type":"code","colab":{}},"source":["def model_train(estimator):\n","  print('Please wait...')\n","  # We'll set sequences to be at most 128 tokens long.\n","  train_features = run_classifier.convert_examples_to_features(\n","      train_examples, label_list, MAX_SEQ_LENGTH, tokenizer)\n","  print('***** Started training at {} *****'.format(datetime.datetime.now()))\n","  print('  Num examples = {}'.format(len(train_examples)))\n","  print('  Batch size = {}'.format(TRAIN_BATCH_SIZE))\n","  tf.logging.info(\"  Num steps = %d\", num_train_steps)\n","  train_input_fn = run_classifier.input_fn_builder(\n","      features=train_features,\n","      seq_length=MAX_SEQ_LENGTH,\n","      is_training=True,\n","      drop_remainder=True)\n","  estimator.train(input_fn=train_input_fn, max_steps=num_train_steps)\n","  print('***** Finished training at {} *****'.format(datetime.datetime.now()))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"uuisjVAKjLfI","colab_type":"code","outputId":"e0570d3f-ebe0-48d3-a162-5f787fe5391d","executionInfo":{"status":"ok","timestamp":1566575657644,"user_tz":-540,"elapsed":279793,"user":{"displayName":"Junha Hyung","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCW-Idc2Xb4naFmTr7ifom9YCmu_ffuOK2Tterv3Q=s64","userId":"06504932993766290160"}},"colab":{"base_uri":"https://localhost:8080/","height":740}},"source":["model_train(estimator)"],"execution_count":8,"outputs":[{"output_type":"stream","text":["W0823 15:51:04.501744 140651498272640 deprecation_wrapper.py:119] From bert_adapter/run_classifier.py:791: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n","\n"],"name":"stderr"},{"output_type":"stream","text":["Please wait...\n","***** Started training at 2019-08-23 15:51:06.558022 *****\n","  Num examples = 8961\n","  Batch size = 32\n"],"name":"stdout"},{"output_type":"stream","text":["W0823 15:51:06.954620 140651498272640 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n","W0823 15:51:12.523654 140651498272640 deprecation_wrapper.py:119] From bert_adapter/modeling.py:174: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n","\n","W0823 15:51:12.529406 140651498272640 deprecation_wrapper.py:119] From bert_adapter/modeling.py:487: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n","\n","W0823 15:51:12.571714 140651498272640 deprecation_wrapper.py:119] From bert_adapter/modeling.py:568: The name tf.assert_less_equal is deprecated. Please use tf.compat.v1.assert_less_equal instead.\n","\n","W0823 15:51:12.601520 140651498272640 deprecation_wrapper.py:119] From bert_adapter/modeling.py:443: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n","\n","W0823 15:51:12.632557 140651498272640 deprecation.py:506] From bert_adapter/modeling.py:435: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n","W0823 15:51:12.657583 140651498272640 deprecation.py:323] From bert_adapter/modeling.py:749: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use keras.layers.dense instead.\n","W0823 15:51:20.111741 140651498272640 deprecation_wrapper.py:119] From bert_adapter/optimization.py:27: The name tf.train.get_or_create_global_step is deprecated. Please use tf.compat.v1.train.get_or_create_global_step instead.\n","\n","W0823 15:51:20.115222 140651498272640 deprecation_wrapper.py:119] From bert_adapter/optimization.py:32: The name tf.train.polynomial_decay is deprecated. Please use tf.compat.v1.train.polynomial_decay instead.\n","\n","W0823 15:51:20.133251 140651498272640 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/optimizer_v2/learning_rate_schedule.py:409: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Deprecated in favor of operator or tf.math.divide.\n","W0823 15:51:20.468208 140651498272640 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1205: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","W0823 15:51:34.346711 140651498272640 deprecation_wrapper.py:119] From bert_adapter/run_classifier.py:673: The name tf.train.init_from_checkpoint is deprecated. Please use tf.compat.v1.train.init_from_checkpoint instead.\n","\n","W0823 15:51:36.226654 140651498272640 deprecation_wrapper.py:119] From bert_adapter/run_classifier.py:674: The name tf.train.Scaffold is deprecated. Please use tf.compat.v1.train.Scaffold instead.\n","\n","W0823 15:52:48.849706 140651498272640 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py:741: Variable.load (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Prefer Variable.assign which has equivalent behavior in 2.X.\n"],"name":"stderr"},{"output_type":"stream","text":["***** Finished training at 2019-08-23 15:54:17.060912 *****\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"d67eZ9kojOA3","colab_type":"code","colab":{}},"source":["def model_eval(estimator):\n","  # Eval the model.\n","  eval_examples = processor.get_dev_examples(TASK_DATA_DIR)\n","  eval_features = run_classifier.convert_examples_to_features(\n","      eval_examples, label_list, MAX_SEQ_LENGTH, tokenizer)\n","  print('***** Started evaluation at {} *****'.format(datetime.datetime.now()))\n","  print('  Num examples = {}'.format(len(eval_examples)))\n","  print('  Batch size = {}'.format(EVAL_BATCH_SIZE))\n","\n","  # Eval will be slightly WRONG on the TPU because it will truncate\n","  # the last batch.\n","  eval_steps = int(len(eval_examples) / EVAL_BATCH_SIZE)\n","  eval_input_fn = run_classifier.input_fn_builder(\n","      features=eval_features,\n","      seq_length=MAX_SEQ_LENGTH,\n","      is_training=False,\n","      drop_remainder=True)\n","  result = estimator.evaluate(input_fn=eval_input_fn, steps=eval_steps)\n","  print('***** Finished evaluation at {} *****'.format(datetime.datetime.now()))\n","  output_eval_file = os.path.join(OUTPUT_DIR, \"eval_results.txt\")\n","  with tf.gfile.GFile(output_eval_file, \"w\") as writer:\n","    print(\"***** Eval results *****\")\n","    for key in sorted(result.keys()):\n","      print('  {} = {}'.format(key, str(result[key])))\n","      writer.write(\"%s = %s\\n\" % (key, str(result[key])))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"rBL1bpJAnV56","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":322},"outputId":"6908ba7f-183d-4e9f-f954-dbcd509564f1","executionInfo":{"status":"ok","timestamp":1566575722471,"user_tz":-540,"elapsed":344608,"user":{"displayName":"Junha Hyung","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCW-Idc2Xb4naFmTr7ifom9YCmu_ffuOK2Tterv3Q=s64","userId":"06504932993766290160"}}},"source":["model_eval(estimator)"],"execution_count":10,"outputs":[{"output_type":"stream","text":["***** Started evaluation at 2019-08-23 15:54:18.223694 *****\n","  Num examples = 2194\n","  Batch size = 8\n"],"name":"stdout"},{"output_type":"stream","text":["W0823 15:54:28.986379 140651498272640 deprecation_wrapper.py:119] From bert_adapter/run_classifier.py:703: The name tf.metrics.accuracy is deprecated. Please use tf.compat.v1.metrics.accuracy instead.\n","\n","W0823 15:54:29.011862 140651498272640 deprecation_wrapper.py:119] From bert_adapter/run_classifier.py:705: The name tf.metrics.mean is deprecated. Please use tf.compat.v1.metrics.mean instead.\n","\n","W0823 15:54:31.212500 140651498272640 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use standard file APIs to check for files with this prefix.\n"],"name":"stderr"},{"output_type":"stream","text":["***** Finished evaluation at 2019-08-23 15:55:21.382209 *****\n","***** Eval results *****\n","  eval_accuracy = 0.602646\n","  eval_loss = 1.0673702\n","  global_step = 840\n","  loss = 1.1026554\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"58CBESPGqUAn","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}